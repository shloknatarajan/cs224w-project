2025-12-09 16:54:50,738 - Using device: cuda
2025-12-09 16:54:50,738 - Logging results to: logs/baselines_20251209_165450/baselines.log
2025-12-09 16:54:50,738 - Loading dataset ogbl-ddi...
2025-12-09 16:54:50,825 - Dataset loaded: 4267 nodes
2025-12-09 16:54:50,970 - Train pos edges: 1067911, Valid pos: 133489, Test pos: 133489
2025-12-09 16:54:50,970 - Valid neg edges: 101882, Test neg: 95599
2025-12-09 16:54:50,990 - Added self-loops: Total edges now = 1072178
2025-12-09 16:54:50,997 - 
================================================================================
2025-12-09 16:54:50,998 - Training Simple GCN Baseline (minimal trainer)
2025-12-09 16:54:50,998 - ================================================================================
2025-12-09 16:54:51,038 - [GCN-Baseline] Starting minimal baseline training (epochs=200, lr=0.01, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 16:54:52,826 - [GCN-Baseline] Epoch 0001 | loss 1.3905 | val@20 0.0139 | test@20 0.0112 | best 0.0139 (ep 1)
2025-12-09 16:54:58,303 - [GCN-Baseline] Epoch 0005 | loss 1.2574 | val@20 0.0237 | test@20 0.0532 | best 0.0237 (ep 5)
2025-12-09 16:55:05,026 - [GCN-Baseline] Epoch 0010 | loss 1.1731 | val@20 0.0313 | test@20 0.0492 | best 0.0313 (ep 10)
2025-12-09 16:55:11,789 - [GCN-Baseline] Epoch 0015 | loss 1.0656 | val@20 0.0548 | test@20 0.0583 | best 0.0548 (ep 15)
2025-12-09 16:55:18,479 - [GCN-Baseline] Epoch 0020 | loss 0.9779 | val@20 0.0622 | test@20 0.0669 | best 0.0622 (ep 20)
2025-12-09 16:55:25,212 - [GCN-Baseline] Epoch 0025 | loss 0.9181 | val@20 0.0505 | test@20 0.0594 | best 0.0622 (ep 20)
2025-12-09 16:55:31,917 - [GCN-Baseline] Epoch 0030 | loss 0.9098 | val@20 0.0267 | test@20 0.0576 | best 0.0622 (ep 20)
2025-12-09 16:55:38,682 - [GCN-Baseline] Epoch 0035 | loss 0.8921 | val@20 0.0387 | test@20 0.0333 | best 0.0622 (ep 20)
2025-12-09 16:55:45,395 - [GCN-Baseline] Epoch 0040 | loss 0.8425 | val@20 0.0261 | test@20 0.0465 | best 0.0622 (ep 20)
2025-12-09 16:55:52,120 - [GCN-Baseline] Epoch 0045 | loss 0.8286 | val@20 0.0423 | test@20 0.0679 | best 0.0622 (ep 20)
2025-12-09 16:55:58,776 - [GCN-Baseline] Epoch 0050 | loss 0.8220 | val@20 0.0608 | test@20 0.0854 | best 0.0622 (ep 20)
2025-12-09 16:56:05,415 - [GCN-Baseline] Epoch 0055 | loss 0.8070 | val@20 0.0244 | test@20 0.0264 | best 0.0622 (ep 20)
2025-12-09 16:56:12,009 - [GCN-Baseline] Epoch 0060 | loss 0.7911 | val@20 0.0282 | test@20 0.0329 | best 0.0622 (ep 20)
2025-12-09 16:56:18,600 - [GCN-Baseline] Epoch 0065 | loss 0.7806 | val@20 0.0321 | test@20 0.0393 | best 0.0622 (ep 20)
2025-12-09 16:56:25,169 - [GCN-Baseline] Epoch 0070 | loss 0.7718 | val@20 0.0642 | test@20 0.0470 | best 0.0642 (ep 70)
2025-12-09 16:56:31,742 - [GCN-Baseline] Epoch 0075 | loss 0.7578 | val@20 0.0322 | test@20 0.0471 | best 0.0642 (ep 70)
2025-12-09 16:56:38,346 - [GCN-Baseline] Epoch 0080 | loss 0.7970 | val@20 0.0931 | test@20 0.1070 | best 0.0931 (ep 80)
2025-12-09 16:56:44,954 - [GCN-Baseline] Epoch 0085 | loss 0.7649 | val@20 0.0541 | test@20 0.0855 | best 0.0931 (ep 80)
2025-12-09 16:56:51,520 - [GCN-Baseline] Epoch 0090 | loss 0.7483 | val@20 0.0426 | test@20 0.0821 | best 0.0931 (ep 80)
2025-12-09 16:56:58,115 - [GCN-Baseline] Epoch 0095 | loss 0.7419 | val@20 0.0577 | test@20 0.0745 | best 0.0931 (ep 80)
2025-12-09 16:57:04,689 - [GCN-Baseline] Epoch 0100 | loss 0.7338 | val@20 0.0536 | test@20 0.0761 | best 0.0931 (ep 80)
2025-12-09 16:57:11,284 - [GCN-Baseline] Epoch 0105 | loss 0.7230 | val@20 0.0494 | test@20 0.0663 | best 0.0931 (ep 80)
2025-12-09 16:57:17,878 - [GCN-Baseline] Epoch 0110 | loss 0.7164 | val@20 0.0531 | test@20 0.0730 | best 0.0931 (ep 80)
2025-12-09 16:57:24,539 - [GCN-Baseline] Epoch 0115 | loss 0.7163 | val@20 0.0580 | test@20 0.0722 | best 0.0931 (ep 80)
2025-12-09 16:57:31,157 - [GCN-Baseline] Epoch 0120 | loss 0.6982 | val@20 0.0636 | test@20 0.0780 | best 0.0931 (ep 80)
2025-12-09 16:57:37,731 - [GCN-Baseline] Epoch 0125 | loss 0.6870 | val@20 0.1173 | test@20 0.1305 | best 0.1173 (ep 125)
2025-12-09 16:57:44,294 - [GCN-Baseline] Epoch 0130 | loss 0.6975 | val@20 0.1260 | test@20 0.1259 | best 0.1260 (ep 130)
2025-12-09 16:57:50,864 - [GCN-Baseline] Epoch 0135 | loss 0.6749 | val@20 0.0839 | test@20 0.0378 | best 0.1260 (ep 130)
2025-12-09 16:57:57,454 - [GCN-Baseline] Epoch 0140 | loss 0.6762 | val@20 0.0490 | test@20 0.0529 | best 0.1260 (ep 130)
2025-12-09 16:58:04,087 - [GCN-Baseline] Epoch 0145 | loss 0.6597 | val@20 0.0749 | test@20 0.0994 | best 0.1260 (ep 130)
2025-12-09 16:58:10,676 - [GCN-Baseline] Epoch 0150 | loss 0.6580 | val@20 0.0591 | test@20 0.0744 | best 0.1260 (ep 130)
2025-12-09 16:58:17,575 - [GCN-Baseline] Epoch 0155 | loss 0.6466 | val@20 0.0453 | test@20 0.0941 | best 0.1260 (ep 130)
2025-12-09 16:58:24,134 - [GCN-Baseline] Epoch 0160 | loss 0.6590 | val@20 0.0436 | test@20 0.1046 | best 0.1260 (ep 130)
2025-12-09 16:58:30,695 - [GCN-Baseline] Epoch 0165 | loss 0.6841 | val@20 0.1116 | test@20 0.1724 | best 0.1260 (ep 130)
2025-12-09 16:58:37,260 - [GCN-Baseline] Epoch 0170 | loss 0.6399 | val@20 0.1228 | test@20 0.1766 | best 0.1260 (ep 130)
2025-12-09 16:58:43,874 - [GCN-Baseline] Epoch 0175 | loss 0.6748 | val@20 0.0883 | test@20 0.0869 | best 0.1260 (ep 130)
2025-12-09 16:58:50,409 - [GCN-Baseline] Epoch 0180 | loss 0.6323 | val@20 0.0667 | test@20 0.1282 | best 0.1260 (ep 130)
2025-12-09 16:58:56,934 - [GCN-Baseline] Epoch 0185 | loss 0.6348 | val@20 0.0514 | test@20 0.0788 | best 0.1260 (ep 130)
2025-12-09 16:59:03,462 - [GCN-Baseline] Epoch 0190 | loss 0.6220 | val@20 0.0651 | test@20 0.0922 | best 0.1260 (ep 130)
2025-12-09 16:59:09,977 - [GCN-Baseline] Epoch 0195 | loss 0.6153 | val@20 0.0377 | test@20 0.0572 | best 0.1260 (ep 130)
2025-12-09 16:59:16,490 - [GCN-Baseline] Epoch 0200 | loss 0.6126 | val@20 0.0578 | test@20 0.0706 | best 0.1260 (ep 130)
2025-12-09 16:59:16,490 - [GCN-Baseline] Done. Best val@20=0.1260 | test@20=0.1259 (epoch 130)
2025-12-09 16:59:16,491 - 
================================================================================
2025-12-09 16:59:16,491 - Training GraphSAGE Baseline (minimal trainer)
2025-12-09 16:59:16,491 - ================================================================================
2025-12-09 16:59:16,530 - [GraphSAGE-Baseline] Starting minimal baseline training (epochs=200, lr=0.01, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 16:59:17,939 - [GraphSAGE-Baseline] Epoch 0001 | loss 1.3899 | val@20 0.0000 | test@20 0.0001 | best 0.0000 (ep 1)
2025-12-09 16:59:23,144 - [GraphSAGE-Baseline] Epoch 0005 | loss 1.3358 | val@20 0.0035 | test@20 0.0036 | best 0.0035 (ep 5)
2025-12-09 16:59:29,682 - [GraphSAGE-Baseline] Epoch 0010 | loss 1.1754 | val@20 0.0010 | test@20 0.0001 | best 0.0035 (ep 5)
2025-12-09 16:59:36,167 - [GraphSAGE-Baseline] Epoch 0015 | loss 0.9891 | val@20 0.0076 | test@20 0.0069 | best 0.0076 (ep 15)
2025-12-09 16:59:42,712 - [GraphSAGE-Baseline] Epoch 0020 | loss 0.9277 | val@20 0.0165 | test@20 0.0165 | best 0.0165 (ep 20)
2025-12-09 16:59:49,352 - [GraphSAGE-Baseline] Epoch 0025 | loss 0.8970 | val@20 0.0044 | test@20 0.0006 | best 0.0165 (ep 20)
2025-12-09 16:59:55,968 - [GraphSAGE-Baseline] Epoch 0030 | loss 0.8686 | val@20 0.0293 | test@20 0.0459 | best 0.0293 (ep 30)
2025-12-09 17:00:02,526 - [GraphSAGE-Baseline] Epoch 0035 | loss 0.8462 | val@20 0.0337 | test@20 0.0446 | best 0.0337 (ep 35)
2025-12-09 17:00:09,039 - [GraphSAGE-Baseline] Epoch 0040 | loss 0.8182 | val@20 0.0532 | test@20 0.0184 | best 0.0532 (ep 40)
2025-12-09 17:00:15,623 - [GraphSAGE-Baseline] Epoch 0045 | loss 0.8239 | val@20 0.0525 | test@20 0.0245 | best 0.0532 (ep 40)
2025-12-09 17:00:22,151 - [GraphSAGE-Baseline] Epoch 0050 | loss 0.8181 | val@20 0.0395 | test@20 0.0553 | best 0.0532 (ep 40)
2025-12-09 17:00:28,793 - [GraphSAGE-Baseline] Epoch 0055 | loss 0.7956 | val@20 0.0187 | test@20 0.0118 | best 0.0532 (ep 40)
2025-12-09 17:00:35,396 - [GraphSAGE-Baseline] Epoch 0060 | loss 0.7618 | val@20 0.0116 | test@20 0.0100 | best 0.0532 (ep 40)
2025-12-09 17:00:41,936 - [GraphSAGE-Baseline] Epoch 0065 | loss 0.7371 | val@20 0.0155 | test@20 0.0180 | best 0.0532 (ep 40)
2025-12-09 17:00:48,474 - [GraphSAGE-Baseline] Epoch 0070 | loss 0.7563 | val@20 0.0736 | test@20 0.0621 | best 0.0736 (ep 70)
2025-12-09 17:00:54,994 - [GraphSAGE-Baseline] Epoch 0075 | loss 0.7312 | val@20 0.0506 | test@20 0.0391 | best 0.0736 (ep 70)
2025-12-09 17:01:01,508 - [GraphSAGE-Baseline] Epoch 0080 | loss 0.7221 | val@20 0.0512 | test@20 0.0393 | best 0.0736 (ep 70)
2025-12-09 17:01:08,092 - [GraphSAGE-Baseline] Epoch 0085 | loss 0.7020 | val@20 0.0621 | test@20 0.0350 | best 0.0736 (ep 70)
2025-12-09 17:01:14,637 - [GraphSAGE-Baseline] Epoch 0090 | loss 0.6878 | val@20 0.1177 | test@20 0.0408 | best 0.1177 (ep 90)
2025-12-09 17:01:21,258 - [GraphSAGE-Baseline] Epoch 0095 | loss 0.6788 | val@20 0.0946 | test@20 0.0283 | best 0.1177 (ep 90)
2025-12-09 17:01:27,815 - [GraphSAGE-Baseline] Epoch 0100 | loss 0.6688 | val@20 0.0666 | test@20 0.0203 | best 0.1177 (ep 90)
2025-12-09 17:01:34,375 - [GraphSAGE-Baseline] Epoch 0105 | loss 0.6588 | val@20 0.0646 | test@20 0.0333 | best 0.1177 (ep 90)
2025-12-09 17:01:40,952 - [GraphSAGE-Baseline] Epoch 0110 | loss 0.6516 | val@20 0.0500 | test@20 0.0304 | best 0.1177 (ep 90)
2025-12-09 17:01:47,547 - [GraphSAGE-Baseline] Epoch 0115 | loss 0.6576 | val@20 0.0404 | test@20 0.0207 | best 0.1177 (ep 90)
2025-12-09 17:01:54,183 - [GraphSAGE-Baseline] Epoch 0120 | loss 0.6435 | val@20 0.0652 | test@20 0.0311 | best 0.1177 (ep 90)
2025-12-09 17:02:00,739 - [GraphSAGE-Baseline] Epoch 0125 | loss 0.6380 | val@20 0.0876 | test@20 0.0583 | best 0.1177 (ep 90)
2025-12-09 17:02:07,213 - [GraphSAGE-Baseline] Epoch 0130 | loss 0.6307 | val@20 0.1090 | test@20 0.0472 | best 0.1177 (ep 90)
2025-12-09 17:02:13,790 - [GraphSAGE-Baseline] Epoch 0135 | loss 0.6388 | val@20 0.0589 | test@20 0.0202 | best 0.1177 (ep 90)
2025-12-09 17:02:20,371 - [GraphSAGE-Baseline] Epoch 0140 | loss 0.6090 | val@20 0.0961 | test@20 0.0394 | best 0.1177 (ep 90)
2025-12-09 17:02:26,960 - [GraphSAGE-Baseline] Epoch 0145 | loss 0.6065 | val@20 0.0685 | test@20 0.0395 | best 0.1177 (ep 90)
2025-12-09 17:02:33,537 - [GraphSAGE-Baseline] Epoch 0150 | loss 0.6767 | val@20 0.0842 | test@20 0.0634 | best 0.1177 (ep 90)
2025-12-09 17:02:40,147 - [GraphSAGE-Baseline] Epoch 0155 | loss 0.6424 | val@20 0.1445 | test@20 0.1021 | best 0.1445 (ep 155)
2025-12-09 17:02:46,771 - [GraphSAGE-Baseline] Epoch 0160 | loss 0.6096 | val@20 0.0208 | test@20 0.0145 | best 0.1445 (ep 155)
2025-12-09 17:02:53,407 - [GraphSAGE-Baseline] Epoch 0165 | loss 0.5921 | val@20 0.0773 | test@20 0.0575 | best 0.1445 (ep 155)
2025-12-09 17:03:00,156 - [GraphSAGE-Baseline] Epoch 0170 | loss 0.5830 | val@20 0.1068 | test@20 0.0635 | best 0.1445 (ep 155)
2025-12-09 17:03:06,782 - [GraphSAGE-Baseline] Epoch 0175 | loss 0.5727 | val@20 0.1205 | test@20 0.1111 | best 0.1445 (ep 155)
2025-12-09 17:03:13,442 - [GraphSAGE-Baseline] Epoch 0180 | loss 0.5642 | val@20 0.0786 | test@20 0.0704 | best 0.1445 (ep 155)
2025-12-09 17:03:20,191 - [GraphSAGE-Baseline] Epoch 0185 | loss 0.5568 | val@20 0.0817 | test@20 0.1028 | best 0.1445 (ep 155)
2025-12-09 17:03:26,834 - [GraphSAGE-Baseline] Epoch 0190 | loss 0.5560 | val@20 0.0702 | test@20 0.0554 | best 0.1445 (ep 155)
2025-12-09 17:03:33,470 - [GraphSAGE-Baseline] Epoch 0195 | loss 0.5544 | val@20 0.0895 | test@20 0.0687 | best 0.1445 (ep 155)
2025-12-09 17:03:40,018 - [GraphSAGE-Baseline] Epoch 0200 | loss 0.5535 | val@20 0.1220 | test@20 0.0820 | best 0.1445 (ep 155)
2025-12-09 17:03:40,018 - [GraphSAGE-Baseline] Done. Best val@20=0.1445 | test@20=0.1021 (epoch 155)
2025-12-09 17:03:40,018 - 
================================================================================
2025-12-09 17:03:40,019 - Training GraphTransformer Baseline (minimal trainer)
2025-12-09 17:03:40,019 - ================================================================================
2025-12-09 17:03:40,058 - [GraphTransformer-Baseline] Starting minimal baseline training (epochs=200, lr=0.005, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 17:03:41,584 - [GraphTransformer-Baseline] Epoch 0001 | loss 1.3865 | val@20 0.0015 | test@20 0.0016 | best 0.0015 (ep 1)
2025-12-09 17:03:47,156 - [GraphTransformer-Baseline] Epoch 0005 | loss 1.3774 | val@20 0.0205 | test@20 0.0114 | best 0.0205 (ep 5)
2025-12-09 17:03:54,093 - [GraphTransformer-Baseline] Epoch 0010 | loss 1.2310 | val@20 0.0313 | test@20 0.0196 | best 0.0313 (ep 10)
2025-12-09 17:04:00,909 - [GraphTransformer-Baseline] Epoch 0015 | loss 1.0695 | val@20 0.0128 | test@20 0.0154 | best 0.0313 (ep 10)
2025-12-09 17:04:07,763 - [GraphTransformer-Baseline] Epoch 0020 | loss 0.9743 | val@20 0.0155 | test@20 0.0211 | best 0.0313 (ep 10)
2025-12-09 17:04:14,614 - [GraphTransformer-Baseline] Epoch 0025 | loss 0.9517 | val@20 0.0189 | test@20 0.0296 | best 0.0313 (ep 10)
2025-12-09 17:04:21,437 - [GraphTransformer-Baseline] Epoch 0030 | loss 0.9233 | val@20 0.0230 | test@20 0.0395 | best 0.0313 (ep 10)
2025-12-09 17:04:28,319 - [GraphTransformer-Baseline] Epoch 0035 | loss 0.9073 | val@20 0.0254 | test@20 0.0461 | best 0.0313 (ep 10)
2025-12-09 17:04:35,161 - [GraphTransformer-Baseline] Epoch 0040 | loss 0.8896 | val@20 0.0323 | test@20 0.0483 | best 0.0323 (ep 40)
2025-12-09 17:04:42,012 - [GraphTransformer-Baseline] Epoch 0045 | loss 0.8723 | val@20 0.0149 | test@20 0.0002 | best 0.0323 (ep 40)
2025-12-09 17:04:48,862 - [GraphTransformer-Baseline] Epoch 0050 | loss 0.8528 | val@20 0.0231 | test@20 0.0299 | best 0.0323 (ep 40)
2025-12-09 17:04:55,675 - [GraphTransformer-Baseline] Epoch 0055 | loss 0.8297 | val@20 0.0200 | test@20 0.0231 | best 0.0323 (ep 40)
2025-12-09 17:05:02,476 - [GraphTransformer-Baseline] Epoch 0060 | loss 0.8148 | val@20 0.0573 | test@20 0.0378 | best 0.0573 (ep 60)
2025-12-09 17:05:09,280 - [GraphTransformer-Baseline] Epoch 0065 | loss 0.8401 | val@20 0.0316 | test@20 0.0060 | best 0.0573 (ep 60)
2025-12-09 17:05:16,136 - [GraphTransformer-Baseline] Epoch 0070 | loss 0.7990 | val@20 0.0225 | test@20 0.0150 | best 0.0573 (ep 60)
2025-12-09 17:05:22,984 - [GraphTransformer-Baseline] Epoch 0075 | loss 0.7821 | val@20 0.0380 | test@20 0.0161 | best 0.0573 (ep 60)
2025-12-09 17:05:29,855 - [GraphTransformer-Baseline] Epoch 0080 | loss 0.7641 | val@20 0.0354 | test@20 0.0420 | best 0.0573 (ep 60)
2025-12-09 17:05:36,709 - [GraphTransformer-Baseline] Epoch 0085 | loss 0.7405 | val@20 0.0476 | test@20 0.0560 | best 0.0573 (ep 60)
2025-12-09 17:05:43,560 - [GraphTransformer-Baseline] Epoch 0090 | loss 0.7269 | val@20 0.0717 | test@20 0.0494 | best 0.0717 (ep 90)
2025-12-09 17:05:50,398 - [GraphTransformer-Baseline] Epoch 0095 | loss 0.7342 | val@20 0.0898 | test@20 0.0356 | best 0.0898 (ep 95)
2025-12-09 17:05:57,295 - [GraphTransformer-Baseline] Epoch 0100 | loss 0.7165 | val@20 0.0466 | test@20 0.0200 | best 0.0898 (ep 95)
2025-12-09 17:06:04,225 - [GraphTransformer-Baseline] Epoch 0105 | loss 0.7044 | val@20 0.0598 | test@20 0.0371 | best 0.0898 (ep 95)
2025-12-09 17:06:11,094 - [GraphTransformer-Baseline] Epoch 0110 | loss 0.6944 | val@20 0.0753 | test@20 0.0263 | best 0.0898 (ep 95)
2025-12-09 17:06:17,937 - [GraphTransformer-Baseline] Epoch 0115 | loss 0.6851 | val@20 0.0783 | test@20 0.0300 | best 0.0898 (ep 95)
2025-12-09 17:06:24,768 - [GraphTransformer-Baseline] Epoch 0120 | loss 0.6784 | val@20 0.0718 | test@20 0.0343 | best 0.0898 (ep 95)
2025-12-09 17:06:31,617 - [GraphTransformer-Baseline] Epoch 0125 | loss 0.6760 | val@20 0.0509 | test@20 0.0258 | best 0.0898 (ep 95)
2025-12-09 17:06:38,452 - [GraphTransformer-Baseline] Epoch 0130 | loss 0.6648 | val@20 0.0355 | test@20 0.0370 | best 0.0898 (ep 95)
2025-12-09 17:06:45,310 - [GraphTransformer-Baseline] Epoch 0135 | loss 0.6592 | val@20 0.0315 | test@20 0.0572 | best 0.0898 (ep 95)
2025-12-09 17:06:52,143 - [GraphTransformer-Baseline] Epoch 0140 | loss 0.6529 | val@20 0.0468 | test@20 0.0518 | best 0.0898 (ep 95)
2025-12-09 17:06:58,986 - [GraphTransformer-Baseline] Epoch 0145 | loss 0.6451 | val@20 0.0597 | test@20 0.0414 | best 0.0898 (ep 95)
2025-12-09 17:07:05,790 - [GraphTransformer-Baseline] Epoch 0150 | loss 0.6721 | val@20 0.1486 | test@20 0.0769 | best 0.1486 (ep 150)
2025-12-09 17:07:12,615 - [GraphTransformer-Baseline] Epoch 0155 | loss 0.6499 | val@20 0.1092 | test@20 0.0680 | best 0.1486 (ep 150)
2025-12-09 17:07:19,430 - [GraphTransformer-Baseline] Epoch 0160 | loss 0.6330 | val@20 0.1507 | test@20 0.1116 | best 0.1507 (ep 160)
2025-12-09 17:07:26,254 - [GraphTransformer-Baseline] Epoch 0165 | loss 0.6204 | val@20 0.1114 | test@20 0.0586 | best 0.1507 (ep 160)
2025-12-09 17:07:33,075 - [GraphTransformer-Baseline] Epoch 0170 | loss 0.6115 | val@20 0.1005 | test@20 0.0600 | best 0.1507 (ep 160)
2025-12-09 17:07:39,898 - [GraphTransformer-Baseline] Epoch 0175 | loss 0.6037 | val@20 0.1054 | test@20 0.0407 | best 0.1507 (ep 160)
2025-12-09 17:07:46,833 - [GraphTransformer-Baseline] Epoch 0180 | loss 0.5902 | val@20 0.1079 | test@20 0.0308 | best 0.1507 (ep 160)
2025-12-09 17:07:53,803 - [GraphTransformer-Baseline] Epoch 0185 | loss 0.5889 | val@20 0.0802 | test@20 0.0226 | best 0.1507 (ep 160)
2025-12-09 17:08:00,767 - [GraphTransformer-Baseline] Epoch 0190 | loss 0.6198 | val@20 0.1632 | test@20 0.0872 | best 0.1632 (ep 190)
2025-12-09 17:08:07,730 - [GraphTransformer-Baseline] Epoch 0195 | loss 0.5818 | val@20 0.0876 | test@20 0.0369 | best 0.1632 (ep 190)
2025-12-09 17:08:14,737 - [GraphTransformer-Baseline] Epoch 0200 | loss 0.5761 | val@20 0.0975 | test@20 0.0778 | best 0.1632 (ep 190)
2025-12-09 17:08:14,737 - [GraphTransformer-Baseline] Done. Best val@20=0.1632 | test@20=0.0872 (epoch 190)
2025-12-09 17:08:14,738 - 
================================================================================
2025-12-09 17:08:14,738 - Training GAT Baseline (minimal trainer)
2025-12-09 17:08:14,738 - ================================================================================
2025-12-09 17:08:14,900 - [GAT-Baseline] Starting minimal baseline training (epochs=200, lr=0.005, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 17:08:16,398 - [GAT-Baseline] Epoch 0001 | loss 1.3890 | val@20 0.0003 | test@20 0.0001 | best 0.0003 (ep 1)
2025-12-09 17:08:21,844 - [GAT-Baseline] Epoch 0005 | loss 1.3854 | val@20 0.0040 | test@20 0.0010 | best 0.0040 (ep 5)
2025-12-09 17:08:28,656 - [GAT-Baseline] Epoch 0010 | loss 1.3566 | val@20 0.0017 | test@20 0.0004 | best 0.0040 (ep 5)
2025-12-09 17:08:35,447 - [GAT-Baseline] Epoch 0015 | loss 1.2744 | val@20 0.0004 | test@20 0.0002 | best 0.0040 (ep 5)
2025-12-09 17:08:42,261 - [GAT-Baseline] Epoch 0020 | loss 1.1863 | val@20 0.0004 | test@20 0.0002 | best 0.0040 (ep 5)
2025-12-09 17:08:49,007 - [GAT-Baseline] Epoch 0025 | loss 1.1417 | val@20 0.0023 | test@20 0.0011 | best 0.0040 (ep 5)
2025-12-09 17:08:55,782 - [GAT-Baseline] Epoch 0030 | loss 1.0906 | val@20 0.0021 | test@20 0.0006 | best 0.0040 (ep 5)
2025-12-09 17:09:02,602 - [GAT-Baseline] Epoch 0035 | loss 1.0177 | val@20 0.0021 | test@20 0.0008 | best 0.0040 (ep 5)
2025-12-09 17:09:09,403 - [GAT-Baseline] Epoch 0040 | loss 0.9869 | val@20 0.0061 | test@20 0.0079 | best 0.0061 (ep 40)
2025-12-09 17:09:16,198 - [GAT-Baseline] Epoch 0045 | loss 1.0362 | val@20 0.0035 | test@20 0.0047 | best 0.0061 (ep 40)
2025-12-09 17:09:23,015 - [GAT-Baseline] Epoch 0050 | loss 0.9813 | val@20 0.0599 | test@20 0.0507 | best 0.0599 (ep 50)
2025-12-09 17:09:29,821 - [GAT-Baseline] Epoch 0055 | loss 0.9726 | val@20 0.0186 | test@20 0.0315 | best 0.0599 (ep 50)
2025-12-09 17:09:36,612 - [GAT-Baseline] Epoch 0060 | loss 0.9647 | val@20 0.0085 | test@20 0.0126 | best 0.0599 (ep 50)
2025-12-09 17:09:43,418 - [GAT-Baseline] Epoch 0065 | loss 0.9537 | val@20 0.0289 | test@20 0.0364 | best 0.0599 (ep 50)
2025-12-09 17:09:50,238 - [GAT-Baseline] Epoch 0070 | loss 0.9482 | val@20 0.0508 | test@20 0.0628 | best 0.0599 (ep 50)
2025-12-09 17:09:57,048 - [GAT-Baseline] Epoch 0075 | loss 0.9245 | val@20 0.0729 | test@20 0.0741 | best 0.0729 (ep 75)
2025-12-09 17:10:03,865 - [GAT-Baseline] Epoch 0080 | loss 0.9064 | val@20 0.0495 | test@20 0.0572 | best 0.0729 (ep 75)
2025-12-09 17:10:10,637 - [GAT-Baseline] Epoch 0085 | loss 0.8946 | val@20 0.0770 | test@20 0.0733 | best 0.0770 (ep 85)
2025-12-09 17:10:17,438 - [GAT-Baseline] Epoch 0090 | loss 0.8842 | val@20 0.1009 | test@20 0.0806 | best 0.1009 (ep 90)
2025-12-09 17:10:24,243 - [GAT-Baseline] Epoch 0095 | loss 0.8654 | val@20 0.0885 | test@20 0.0754 | best 0.1009 (ep 90)
2025-12-09 17:10:31,050 - [GAT-Baseline] Epoch 0100 | loss 0.8576 | val@20 0.0904 | test@20 0.0783 | best 0.1009 (ep 90)
2025-12-09 17:10:37,840 - [GAT-Baseline] Epoch 0105 | loss 0.8471 | val@20 0.0939 | test@20 0.0943 | best 0.1009 (ep 90)
2025-12-09 17:10:44,646 - [GAT-Baseline] Epoch 0110 | loss 0.8407 | val@20 0.0964 | test@20 0.0812 | best 0.1009 (ep 90)
2025-12-09 17:10:51,505 - [GAT-Baseline] Epoch 0115 | loss 0.8272 | val@20 0.0782 | test@20 0.0732 | best 0.1009 (ep 90)
2025-12-09 17:10:58,326 - [GAT-Baseline] Epoch 0120 | loss 0.8148 | val@20 0.0626 | test@20 0.0528 | best 0.1009 (ep 90)
2025-12-09 17:11:05,170 - [GAT-Baseline] Epoch 0125 | loss 0.8090 | val@20 0.0517 | test@20 0.0481 | best 0.1009 (ep 90)
2025-12-09 17:11:12,027 - [GAT-Baseline] Epoch 0130 | loss 0.8085 | val@20 0.0479 | test@20 0.0497 | best 0.1009 (ep 90)
2025-12-09 17:11:18,873 - [GAT-Baseline] Epoch 0135 | loss 0.7985 | val@20 0.0527 | test@20 0.0481 | best 0.1009 (ep 90)
2025-12-09 17:11:25,702 - [GAT-Baseline] Epoch 0140 | loss 0.8082 | val@20 0.0709 | test@20 0.0606 | best 0.1009 (ep 90)
2025-12-09 17:11:32,562 - [GAT-Baseline] Epoch 0145 | loss 0.7903 | val@20 0.0595 | test@20 0.0425 | best 0.1009 (ep 90)
2025-12-09 17:11:39,474 - [GAT-Baseline] Epoch 0150 | loss 0.7834 | val@20 0.0548 | test@20 0.0528 | best 0.1009 (ep 90)
2025-12-09 17:11:47,731 - [GAT-Baseline] Epoch 0155 | loss 0.7851 | val@20 0.0644 | test@20 0.0584 | best 0.1009 (ep 90)
2025-12-09 17:11:55,729 - [GAT-Baseline] Epoch 0160 | loss 0.7693 | val@20 0.0385 | test@20 0.0385 | best 0.1009 (ep 90)
2025-12-09 17:12:02,668 - [GAT-Baseline] Epoch 0165 | loss 0.8027 | val@20 0.0772 | test@20 0.0587 | best 0.1009 (ep 90)
2025-12-09 17:12:11,092 - [GAT-Baseline] Epoch 0170 | loss 0.7847 | val@20 0.0460 | test@20 0.0561 | best 0.1009 (ep 90)
2025-12-09 17:12:18,750 - [GAT-Baseline] Epoch 0175 | loss 0.7617 | val@20 0.0389 | test@20 0.0442 | best 0.1009 (ep 90)
2025-12-09 17:12:25,678 - [GAT-Baseline] Epoch 0180 | loss 0.7568 | val@20 0.0669 | test@20 0.0525 | best 0.1009 (ep 90)
2025-12-09 17:12:32,976 - [GAT-Baseline] Epoch 0185 | loss 0.7510 | val@20 0.0639 | test@20 0.0369 | best 0.1009 (ep 90)
2025-12-09 17:12:39,922 - [GAT-Baseline] Epoch 0190 | loss 0.7418 | val@20 0.0654 | test@20 0.0431 | best 0.1009 (ep 90)
2025-12-09 17:12:39,923 - [GAT-Baseline] Early stopping at epoch 190 (no val improvement for 20 evals)
2025-12-09 17:12:39,923 - [GAT-Baseline] Done. Best val@20=0.1009 | test@20=0.0806 (epoch 90)
2025-12-09 17:12:39,923 - 
================================================================================
2025-12-09 17:12:39,923 - FINAL RESULTS - BASELINES
2025-12-09 17:12:39,923 - ================================================================================
2025-12-09 17:12:39,923 - GCN:
2025-12-09 17:12:39,923 -   Validation Hits@20: 0.1260
2025-12-09 17:12:39,924 -   Test Hits@20: 0.1259
2025-12-09 17:12:39,924 -   Val-Test Gap: 0.0000 (0.0% relative)
2025-12-09 17:12:39,924 - GraphSAGE:
2025-12-09 17:12:39,924 -   Validation Hits@20: 0.1445
2025-12-09 17:12:39,924 -   Test Hits@20: 0.1021
2025-12-09 17:12:39,924 -   Val-Test Gap: 0.0423 (29.3% relative)
2025-12-09 17:12:39,924 - GraphTransformer:
2025-12-09 17:12:39,924 -   Validation Hits@20: 0.1632
2025-12-09 17:12:39,924 -   Test Hits@20: 0.0872
2025-12-09 17:12:39,924 -   Val-Test Gap: 0.0760 (46.6% relative)
2025-12-09 17:12:39,924 - GAT:
2025-12-09 17:12:39,924 -   Validation Hits@20: 0.1009
2025-12-09 17:12:39,924 -   Test Hits@20: 0.0806
2025-12-09 17:12:39,924 -   Val-Test Gap: 0.0203 (20.1% relative)
2025-12-09 17:12:39,924 - ================================================================================
2025-12-09 17:12:39,925 - Results logged to: logs/baselines_20251209_165450/baselines.log
