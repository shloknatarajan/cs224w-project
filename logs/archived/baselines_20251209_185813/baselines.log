2025-12-09 18:58:13,843 - Using device: cuda
2025-12-09 18:58:13,843 - Logging results to: logs/baselines_20251209_185813/baselines.log
2025-12-09 18:58:13,843 - Loading dataset ogbl-ddi...
2025-12-09 18:58:13,930 - Dataset loaded: 4267 nodes
2025-12-09 18:58:14,110 - Train pos edges: 1067911, Valid pos: 133489, Test pos: 133489
2025-12-09 18:58:14,110 - Valid neg edges: 101882, Test neg: 95599
2025-12-09 18:58:14,130 - Added self-loops: Total edges now = 1072178
2025-12-09 18:58:14,140 - 
================================================================================
2025-12-09 18:58:14,141 - Training Simple GCN Baseline (minimal trainer)
2025-12-09 18:58:14,141 - ================================================================================
2025-12-09 18:58:14,193 - [GCN-Baseline] Starting minimal baseline training (epochs=200, lr=0.01, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 18:58:15,853 - [GCN-Baseline] Epoch 0001 | loss 1.3878 | val@20 0.0036 | test@20 0.0014 | best 0.0036 (ep 1)
2025-12-09 18:58:21,053 - [GCN-Baseline] Epoch 0005 | loss 1.3035 | val@20 0.0183 | test@20 0.0418 | best 0.0183 (ep 5)
2025-12-09 18:58:27,507 - [GCN-Baseline] Epoch 0010 | loss 1.1924 | val@20 0.0276 | test@20 0.0583 | best 0.0276 (ep 10)
2025-12-09 18:58:33,929 - [GCN-Baseline] Epoch 0015 | loss 1.0664 | val@20 0.0001 | test@20 0.0002 | best 0.0276 (ep 10)
2025-12-09 18:58:40,376 - [GCN-Baseline] Epoch 0020 | loss 0.9960 | val@20 0.0256 | test@20 0.0521 | best 0.0276 (ep 10)
2025-12-09 18:58:46,811 - [GCN-Baseline] Epoch 0025 | loss 0.9205 | val@20 0.0524 | test@20 0.0506 | best 0.0524 (ep 25)
2025-12-09 18:58:53,288 - [GCN-Baseline] Epoch 0030 | loss 0.9094 | val@20 0.0133 | test@20 0.0070 | best 0.0524 (ep 25)
2025-12-09 18:58:59,769 - [GCN-Baseline] Epoch 0035 | loss 0.9465 | val@20 0.0274 | test@20 0.0505 | best 0.0524 (ep 25)
2025-12-09 18:59:06,277 - [GCN-Baseline] Epoch 0040 | loss 0.9304 | val@20 0.0489 | test@20 0.0356 | best 0.0524 (ep 25)
2025-12-09 18:59:12,761 - [GCN-Baseline] Epoch 0045 | loss 0.8821 | val@20 0.0434 | test@20 0.0163 | best 0.0524 (ep 25)
2025-12-09 18:59:19,205 - [GCN-Baseline] Epoch 0050 | loss 0.8597 | val@20 0.0328 | test@20 0.0398 | best 0.0524 (ep 25)
2025-12-09 18:59:25,663 - [GCN-Baseline] Epoch 0055 | loss 0.8376 | val@20 0.0260 | test@20 0.0366 | best 0.0524 (ep 25)
2025-12-09 18:59:32,141 - [GCN-Baseline] Epoch 0060 | loss 0.8077 | val@20 0.0175 | test@20 0.0131 | best 0.0524 (ep 25)
2025-12-09 18:59:38,602 - [GCN-Baseline] Epoch 0065 | loss 0.7911 | val@20 0.0426 | test@20 0.0316 | best 0.0524 (ep 25)
2025-12-09 18:59:45,110 - [GCN-Baseline] Epoch 0070 | loss 0.7771 | val@20 0.0629 | test@20 0.0522 | best 0.0629 (ep 70)
2025-12-09 18:59:51,587 - [GCN-Baseline] Epoch 0075 | loss 0.7637 | val@20 0.0428 | test@20 0.0337 | best 0.0629 (ep 70)
2025-12-09 18:59:58,065 - [GCN-Baseline] Epoch 0080 | loss 0.8110 | val@20 0.0238 | test@20 0.0236 | best 0.0629 (ep 70)
2025-12-09 19:00:04,690 - [GCN-Baseline] Epoch 0085 | loss 0.7851 | val@20 0.1112 | test@20 0.1059 | best 0.1112 (ep 85)
2025-12-09 19:00:11,158 - [GCN-Baseline] Epoch 0090 | loss 0.7738 | val@20 0.1234 | test@20 0.1517 | best 0.1234 (ep 90)
2025-12-09 19:00:17,670 - [GCN-Baseline] Epoch 0095 | loss 0.7618 | val@20 0.0236 | test@20 0.0301 | best 0.1234 (ep 90)
2025-12-09 19:00:24,147 - [GCN-Baseline] Epoch 0100 | loss 0.7487 | val@20 0.0356 | test@20 0.0129 | best 0.1234 (ep 90)
2025-12-09 19:00:30,619 - [GCN-Baseline] Epoch 0105 | loss 0.7375 | val@20 0.0341 | test@20 0.0551 | best 0.1234 (ep 90)
2025-12-09 19:00:37,096 - [GCN-Baseline] Epoch 0110 | loss 0.7300 | val@20 0.0255 | test@20 0.0425 | best 0.1234 (ep 90)
2025-12-09 19:00:43,604 - [GCN-Baseline] Epoch 0115 | loss 0.7215 | val@20 0.0255 | test@20 0.0291 | best 0.1234 (ep 90)
2025-12-09 19:00:50,055 - [GCN-Baseline] Epoch 0120 | loss 0.7144 | val@20 0.0108 | test@20 0.0028 | best 0.1234 (ep 90)
2025-12-09 19:00:56,514 - [GCN-Baseline] Epoch 0125 | loss 0.7026 | val@20 0.0078 | test@20 0.0015 | best 0.1234 (ep 90)
2025-12-09 19:01:03,529 - [GCN-Baseline] Epoch 0130 | loss 0.7929 | val@20 0.0379 | test@20 0.0694 | best 0.1234 (ep 90)
2025-12-09 19:01:10,797 - [GCN-Baseline] Epoch 0135 | loss 0.7063 | val@20 0.1359 | test@20 0.1102 | best 0.1359 (ep 135)
2025-12-09 19:01:17,346 - [GCN-Baseline] Epoch 0140 | loss 0.7142 | val@20 0.0360 | test@20 0.0230 | best 0.1359 (ep 135)
2025-12-09 19:01:23,821 - [GCN-Baseline] Epoch 0145 | loss 0.6866 | val@20 0.0241 | test@20 0.0165 | best 0.1359 (ep 135)
2025-12-09 19:01:30,333 - [GCN-Baseline] Epoch 0150 | loss 0.6782 | val@20 0.0474 | test@20 0.0323 | best 0.1359 (ep 135)
2025-12-09 19:01:36,862 - [GCN-Baseline] Epoch 0155 | loss 0.6707 | val@20 0.0220 | test@20 0.0185 | best 0.1359 (ep 135)
2025-12-09 19:01:43,341 - [GCN-Baseline] Epoch 0160 | loss 0.6612 | val@20 0.0184 | test@20 0.0255 | best 0.1359 (ep 135)
2025-12-09 19:01:49,893 - [GCN-Baseline] Epoch 0165 | loss 0.6733 | val@20 0.0348 | test@20 0.0500 | best 0.1359 (ep 135)
2025-12-09 19:01:56,371 - [GCN-Baseline] Epoch 0170 | loss 0.6834 | val@20 0.0246 | test@20 0.0277 | best 0.1359 (ep 135)
2025-12-09 19:02:02,961 - [GCN-Baseline] Epoch 0175 | loss 0.6682 | val@20 0.0315 | test@20 0.0260 | best 0.1359 (ep 135)
2025-12-09 19:02:09,564 - [GCN-Baseline] Epoch 0180 | loss 0.6468 | val@20 0.0366 | test@20 0.0319 | best 0.1359 (ep 135)
2025-12-09 19:02:16,074 - [GCN-Baseline] Epoch 0185 | loss 0.6448 | val@20 0.0298 | test@20 0.0343 | best 0.1359 (ep 135)
2025-12-09 19:02:22,585 - [GCN-Baseline] Epoch 0190 | loss 0.6399 | val@20 0.0263 | test@20 0.0420 | best 0.1359 (ep 135)
2025-12-09 19:02:29,081 - [GCN-Baseline] Epoch 0195 | loss 0.6403 | val@20 0.0274 | test@20 0.0358 | best 0.1359 (ep 135)
2025-12-09 19:02:35,576 - [GCN-Baseline] Epoch 0200 | loss 0.6394 | val@20 0.0282 | test@20 0.0340 | best 0.1359 (ep 135)
2025-12-09 19:02:35,576 - [GCN-Baseline] Done. Best val@20=0.1359 | test@20=0.1102 (epoch 135)
2025-12-09 19:02:35,577 - 
================================================================================
2025-12-09 19:02:35,577 - Training GraphSAGE Baseline (minimal trainer)
2025-12-09 19:02:35,577 - ================================================================================
2025-12-09 19:02:35,622 - [GraphSAGE-Baseline] Starting minimal baseline training (epochs=200, lr=0.01, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 19:02:37,026 - [GraphSAGE-Baseline] Epoch 0001 | loss 1.3915 | val@20 0.0020 | test@20 0.0019 | best 0.0020 (ep 1)
2025-12-09 19:02:42,193 - [GraphSAGE-Baseline] Epoch 0005 | loss 1.3058 | val@20 0.0034 | test@20 0.0018 | best 0.0034 (ep 5)
2025-12-09 19:02:48,635 - [GraphSAGE-Baseline] Epoch 0010 | loss 1.1913 | val@20 0.0028 | test@20 0.0059 | best 0.0034 (ep 5)
2025-12-09 19:02:55,082 - [GraphSAGE-Baseline] Epoch 0015 | loss 1.0479 | val@20 0.0004 | test@20 0.0000 | best 0.0034 (ep 5)
2025-12-09 19:03:01,578 - [GraphSAGE-Baseline] Epoch 0020 | loss 1.0341 | val@20 0.0102 | test@20 0.0126 | best 0.0102 (ep 20)
2025-12-09 19:03:08,137 - [GraphSAGE-Baseline] Epoch 0025 | loss 0.9245 | val@20 0.0178 | test@20 0.0259 | best 0.0178 (ep 25)
2025-12-09 19:03:14,581 - [GraphSAGE-Baseline] Epoch 0030 | loss 0.8962 | val@20 0.0275 | test@20 0.0572 | best 0.0275 (ep 30)
2025-12-09 19:03:21,019 - [GraphSAGE-Baseline] Epoch 0035 | loss 0.8615 | val@20 0.0168 | test@20 0.0077 | best 0.0275 (ep 30)
2025-12-09 19:03:27,425 - [GraphSAGE-Baseline] Epoch 0040 | loss 0.8554 | val@20 0.0337 | test@20 0.0290 | best 0.0337 (ep 40)
2025-12-09 19:03:33,870 - [GraphSAGE-Baseline] Epoch 0045 | loss 0.8149 | val@20 0.0232 | test@20 0.0167 | best 0.0337 (ep 40)
2025-12-09 19:03:40,337 - [GraphSAGE-Baseline] Epoch 0050 | loss 0.7937 | val@20 0.0244 | test@20 0.0226 | best 0.0337 (ep 40)
2025-12-09 19:03:46,775 - [GraphSAGE-Baseline] Epoch 0055 | loss 0.7772 | val@20 0.0351 | test@20 0.0080 | best 0.0351 (ep 55)
2025-12-09 19:03:53,191 - [GraphSAGE-Baseline] Epoch 0060 | loss 0.8442 | val@20 0.0459 | test@20 0.0104 | best 0.0459 (ep 60)
2025-12-09 19:03:59,641 - [GraphSAGE-Baseline] Epoch 0065 | loss 0.7643 | val@20 0.0281 | test@20 0.0241 | best 0.0459 (ep 60)
2025-12-09 19:04:06,203 - [GraphSAGE-Baseline] Epoch 0070 | loss 0.7466 | val@20 0.0844 | test@20 0.0625 | best 0.0844 (ep 70)
2025-12-09 19:04:12,593 - [GraphSAGE-Baseline] Epoch 0075 | loss 0.7286 | val@20 0.0650 | test@20 0.0241 | best 0.0844 (ep 70)
2025-12-09 19:04:19,021 - [GraphSAGE-Baseline] Epoch 0080 | loss 0.7086 | val@20 0.0961 | test@20 0.0446 | best 0.0961 (ep 80)
2025-12-09 19:04:25,442 - [GraphSAGE-Baseline] Epoch 0085 | loss 0.6882 | val@20 0.0550 | test@20 0.0491 | best 0.0961 (ep 80)
2025-12-09 19:04:31,892 - [GraphSAGE-Baseline] Epoch 0090 | loss 0.6802 | val@20 0.0442 | test@20 0.0541 | best 0.0961 (ep 80)
2025-12-09 19:04:38,366 - [GraphSAGE-Baseline] Epoch 0095 | loss 0.6687 | val@20 0.0813 | test@20 0.0545 | best 0.0961 (ep 80)
2025-12-09 19:04:44,810 - [GraphSAGE-Baseline] Epoch 0100 | loss 0.6723 | val@20 0.0841 | test@20 0.0361 | best 0.0961 (ep 80)
2025-12-09 19:04:51,305 - [GraphSAGE-Baseline] Epoch 0105 | loss 0.6578 | val@20 0.0477 | test@20 0.0583 | best 0.0961 (ep 80)
2025-12-09 19:04:57,725 - [GraphSAGE-Baseline] Epoch 0110 | loss 0.6781 | val@20 0.0864 | test@20 0.0378 | best 0.0961 (ep 80)
2025-12-09 19:05:04,223 - [GraphSAGE-Baseline] Epoch 0115 | loss 0.6534 | val@20 0.0503 | test@20 0.0110 | best 0.0961 (ep 80)
2025-12-09 19:05:10,785 - [GraphSAGE-Baseline] Epoch 0120 | loss 0.6418 | val@20 0.0556 | test@20 0.0462 | best 0.0961 (ep 80)
2025-12-09 19:05:17,211 - [GraphSAGE-Baseline] Epoch 0125 | loss 0.6311 | val@20 0.0582 | test@20 0.0473 | best 0.0961 (ep 80)
2025-12-09 19:05:23,645 - [GraphSAGE-Baseline] Epoch 0130 | loss 0.6217 | val@20 0.0347 | test@20 0.0230 | best 0.0961 (ep 80)
2025-12-09 19:05:30,100 - [GraphSAGE-Baseline] Epoch 0135 | loss 0.6098 | val@20 0.0468 | test@20 0.0254 | best 0.0961 (ep 80)
2025-12-09 19:05:36,541 - [GraphSAGE-Baseline] Epoch 0140 | loss 0.6023 | val@20 0.0379 | test@20 0.0352 | best 0.0961 (ep 80)
2025-12-09 19:05:43,001 - [GraphSAGE-Baseline] Epoch 0145 | loss 0.5976 | val@20 0.0495 | test@20 0.0379 | best 0.0961 (ep 80)
2025-12-09 19:05:49,437 - [GraphSAGE-Baseline] Epoch 0150 | loss 0.5883 | val@20 0.0649 | test@20 0.0239 | best 0.0961 (ep 80)
2025-12-09 19:05:55,879 - [GraphSAGE-Baseline] Epoch 0155 | loss 0.5813 | val@20 0.0560 | test@20 0.0263 | best 0.0961 (ep 80)
2025-12-09 19:06:02,321 - [GraphSAGE-Baseline] Epoch 0160 | loss 0.6088 | val@20 0.0924 | test@20 0.0575 | best 0.0961 (ep 80)
2025-12-09 19:06:08,917 - [GraphSAGE-Baseline] Epoch 0165 | loss 0.5938 | val@20 0.0573 | test@20 0.0166 | best 0.0961 (ep 80)
2025-12-09 19:06:15,361 - [GraphSAGE-Baseline] Epoch 0170 | loss 0.5813 | val@20 0.0748 | test@20 0.0318 | best 0.0961 (ep 80)
2025-12-09 19:06:21,803 - [GraphSAGE-Baseline] Epoch 0175 | loss 0.5702 | val@20 0.0442 | test@20 0.0203 | best 0.0961 (ep 80)
2025-12-09 19:06:28,227 - [GraphSAGE-Baseline] Epoch 0180 | loss 0.5600 | val@20 0.0455 | test@20 0.0289 | best 0.0961 (ep 80)
2025-12-09 19:06:28,227 - [GraphSAGE-Baseline] Early stopping at epoch 180 (no val improvement for 20 evals)
2025-12-09 19:06:28,227 - [GraphSAGE-Baseline] Done. Best val@20=0.0961 | test@20=0.0446 (epoch 80)
2025-12-09 19:06:28,228 - 
================================================================================
2025-12-09 19:06:28,228 - Training GraphTransformer Baseline (minimal trainer)
2025-12-09 19:06:28,228 - ================================================================================
2025-12-09 19:06:28,280 - [GraphTransformer-Baseline] Starting minimal baseline training (epochs=200, lr=0.005, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 19:06:29,896 - [GraphTransformer-Baseline] Epoch 0001 | loss 1.3896 | val@20 0.0040 | test@20 0.0026 | best 0.0040 (ep 1)
2025-12-09 19:06:35,583 - [GraphTransformer-Baseline] Epoch 0005 | loss 1.3713 | val@20 0.0278 | test@20 0.0053 | best 0.0278 (ep 5)
2025-12-09 19:06:42,629 - [GraphTransformer-Baseline] Epoch 0010 | loss 1.2441 | val@20 0.0121 | test@20 0.0064 | best 0.0278 (ep 5)
2025-12-09 19:06:49,636 - [GraphTransformer-Baseline] Epoch 0015 | loss 1.1567 | val@20 0.0062 | test@20 0.0049 | best 0.0278 (ep 5)
2025-12-09 19:06:56,671 - [GraphTransformer-Baseline] Epoch 0020 | loss 1.0254 | val@20 0.0070 | test@20 0.0058 | best 0.0278 (ep 5)
2025-12-09 19:07:03,750 - [GraphTransformer-Baseline] Epoch 0025 | loss 0.9632 | val@20 0.0078 | test@20 0.0082 | best 0.0278 (ep 5)
2025-12-09 19:07:10,837 - [GraphTransformer-Baseline] Epoch 0030 | loss 0.9376 | val@20 0.0102 | test@20 0.0118 | best 0.0278 (ep 5)
2025-12-09 19:07:17,890 - [GraphTransformer-Baseline] Epoch 0035 | loss 0.9068 | val@20 0.0151 | test@20 0.0203 | best 0.0278 (ep 5)
2025-12-09 19:07:24,936 - [GraphTransformer-Baseline] Epoch 0040 | loss 0.8797 | val@20 0.0275 | test@20 0.0377 | best 0.0278 (ep 5)
2025-12-09 19:07:31,941 - [GraphTransformer-Baseline] Epoch 0045 | loss 0.8468 | val@20 0.0150 | test@20 0.0161 | best 0.0278 (ep 5)
2025-12-09 19:07:38,964 - [GraphTransformer-Baseline] Epoch 0050 | loss 0.8215 | val@20 0.0574 | test@20 0.0246 | best 0.0574 (ep 50)
2025-12-09 19:07:46,051 - [GraphTransformer-Baseline] Epoch 0055 | loss 0.8114 | val@20 0.0681 | test@20 0.0363 | best 0.0681 (ep 55)
2025-12-09 19:07:53,127 - [GraphTransformer-Baseline] Epoch 0060 | loss 0.8152 | val@20 0.0543 | test@20 0.0262 | best 0.0681 (ep 55)
2025-12-09 19:08:00,160 - [GraphTransformer-Baseline] Epoch 0065 | loss 0.7836 | val@20 0.0260 | test@20 0.0299 | best 0.0681 (ep 55)
2025-12-09 19:08:07,353 - [GraphTransformer-Baseline] Epoch 0070 | loss 0.7671 | val@20 0.0456 | test@20 0.0598 | best 0.0681 (ep 55)
2025-12-09 19:08:14,383 - [GraphTransformer-Baseline] Epoch 0075 | loss 0.7589 | val@20 0.0647 | test@20 0.0506 | best 0.0681 (ep 55)
2025-12-09 19:08:21,386 - [GraphTransformer-Baseline] Epoch 0080 | loss 0.7437 | val@20 0.0312 | test@20 0.0359 | best 0.0681 (ep 55)
2025-12-09 19:08:28,398 - [GraphTransformer-Baseline] Epoch 0085 | loss 0.7292 | val@20 0.0334 | test@20 0.0404 | best 0.0681 (ep 55)
2025-12-09 19:08:35,442 - [GraphTransformer-Baseline] Epoch 0090 | loss 0.7151 | val@20 0.0334 | test@20 0.0395 | best 0.0681 (ep 55)
2025-12-09 19:08:42,482 - [GraphTransformer-Baseline] Epoch 0095 | loss 0.7102 | val@20 0.0425 | test@20 0.0233 | best 0.0681 (ep 55)
2025-12-09 19:08:49,468 - [GraphTransformer-Baseline] Epoch 0100 | loss 0.6943 | val@20 0.0793 | test@20 0.0348 | best 0.0793 (ep 100)
2025-12-09 19:08:56,465 - [GraphTransformer-Baseline] Epoch 0105 | loss 0.6886 | val@20 0.0750 | test@20 0.0332 | best 0.0793 (ep 100)
2025-12-09 19:09:03,555 - [GraphTransformer-Baseline] Epoch 0110 | loss 0.6836 | val@20 0.0755 | test@20 0.0332 | best 0.0793 (ep 100)
2025-12-09 19:09:10,604 - [GraphTransformer-Baseline] Epoch 0115 | loss 0.6794 | val@20 0.0449 | test@20 0.0322 | best 0.0793 (ep 100)
2025-12-09 19:09:17,600 - [GraphTransformer-Baseline] Epoch 0120 | loss 0.6755 | val@20 0.0357 | test@20 0.0294 | best 0.0793 (ep 100)
2025-12-09 19:09:24,640 - [GraphTransformer-Baseline] Epoch 0125 | loss 0.6765 | val@20 0.0434 | test@20 0.0302 | best 0.0793 (ep 100)
2025-12-09 19:09:31,620 - [GraphTransformer-Baseline] Epoch 0130 | loss 0.6706 | val@20 0.0351 | test@20 0.0299 | best 0.0793 (ep 100)
2025-12-09 19:09:38,646 - [GraphTransformer-Baseline] Epoch 0135 | loss 0.6678 | val@20 0.0291 | test@20 0.0222 | best 0.0793 (ep 100)
2025-12-09 19:09:45,663 - [GraphTransformer-Baseline] Epoch 0140 | loss 0.6775 | val@20 0.0307 | test@20 0.0241 | best 0.0793 (ep 100)
2025-12-09 19:09:52,638 - [GraphTransformer-Baseline] Epoch 0145 | loss 0.6833 | val@20 0.0735 | test@20 0.0147 | best 0.0793 (ep 100)
2025-12-09 19:09:59,671 - [GraphTransformer-Baseline] Epoch 0150 | loss 0.6946 | val@20 0.1166 | test@20 0.0373 | best 0.1166 (ep 150)
2025-12-09 19:10:06,757 - [GraphTransformer-Baseline] Epoch 0155 | loss 0.6653 | val@20 0.0570 | test@20 0.0248 | best 0.1166 (ep 150)
2025-12-09 19:10:13,792 - [GraphTransformer-Baseline] Epoch 0160 | loss 0.6666 | val@20 0.0571 | test@20 0.0114 | best 0.1166 (ep 150)
2025-12-09 19:10:20,830 - [GraphTransformer-Baseline] Epoch 0165 | loss 0.6539 | val@20 0.0633 | test@20 0.0372 | best 0.1166 (ep 150)
2025-12-09 19:10:27,838 - [GraphTransformer-Baseline] Epoch 0170 | loss 0.6443 | val@20 0.0565 | test@20 0.0269 | best 0.1166 (ep 150)
2025-12-09 19:10:34,845 - [GraphTransformer-Baseline] Epoch 0175 | loss 0.6377 | val@20 0.0572 | test@20 0.0187 | best 0.1166 (ep 150)
2025-12-09 19:10:41,827 - [GraphTransformer-Baseline] Epoch 0180 | loss 0.6261 | val@20 0.0876 | test@20 0.0182 | best 0.1166 (ep 150)
2025-12-09 19:10:48,852 - [GraphTransformer-Baseline] Epoch 0185 | loss 0.6150 | val@20 0.0858 | test@20 0.0241 | best 0.1166 (ep 150)
2025-12-09 19:10:55,869 - [GraphTransformer-Baseline] Epoch 0190 | loss 0.6332 | val@20 0.1035 | test@20 0.0335 | best 0.1166 (ep 150)
2025-12-09 19:11:03,311 - [GraphTransformer-Baseline] Epoch 0195 | loss 0.6599 | val@20 0.0414 | test@20 0.0105 | best 0.1166 (ep 150)
2025-12-09 19:11:10,633 - [GraphTransformer-Baseline] Epoch 0200 | loss 0.6468 | val@20 0.0956 | test@20 0.0371 | best 0.1166 (ep 150)
2025-12-09 19:11:10,633 - [GraphTransformer-Baseline] Done. Best val@20=0.1166 | test@20=0.0373 (epoch 150)
2025-12-09 19:11:10,634 - 
================================================================================
2025-12-09 19:11:10,634 - Training GAT Baseline (minimal trainer)
2025-12-09 19:11:10,634 - ================================================================================
2025-12-09 19:11:10,739 - [GAT-Baseline] Starting minimal baseline training (epochs=200, lr=0.005, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 19:11:12,269 - [GAT-Baseline] Epoch 0001 | loss 1.3879 | val@20 0.0110 | test@20 0.0038 | best 0.0110 (ep 1)
2025-12-09 19:11:17,631 - [GAT-Baseline] Epoch 0005 | loss 1.3855 | val@20 0.0030 | test@20 0.0009 | best 0.0110 (ep 1)
2025-12-09 19:11:24,338 - [GAT-Baseline] Epoch 0010 | loss 1.3615 | val@20 0.0027 | test@20 0.0009 | best 0.0110 (ep 1)
2025-12-09 19:11:31,039 - [GAT-Baseline] Epoch 0015 | loss 1.2815 | val@20 0.0052 | test@20 0.0028 | best 0.0110 (ep 1)
2025-12-09 19:11:37,696 - [GAT-Baseline] Epoch 0020 | loss 1.1873 | val@20 0.0029 | test@20 0.0021 | best 0.0110 (ep 1)
2025-12-09 19:11:44,472 - [GAT-Baseline] Epoch 0025 | loss 1.2315 | val@20 0.0038 | test@20 0.0016 | best 0.0110 (ep 1)
2025-12-09 19:11:51,166 - [GAT-Baseline] Epoch 0030 | loss 1.1155 | val@20 0.0037 | test@20 0.0016 | best 0.0110 (ep 1)
2025-12-09 19:11:57,834 - [GAT-Baseline] Epoch 0035 | loss 1.0665 | val@20 0.0063 | test@20 0.0025 | best 0.0110 (ep 1)
2025-12-09 19:12:04,611 - [GAT-Baseline] Epoch 0040 | loss 1.0452 | val@20 0.0047 | test@20 0.0034 | best 0.0110 (ep 1)
2025-12-09 19:12:11,363 - [GAT-Baseline] Epoch 0045 | loss 1.0111 | val@20 0.0020 | test@20 0.0019 | best 0.0110 (ep 1)
2025-12-09 19:12:18,037 - [GAT-Baseline] Epoch 0050 | loss 0.9644 | val@20 0.0008 | test@20 0.0006 | best 0.0110 (ep 1)
2025-12-09 19:12:24,701 - [GAT-Baseline] Epoch 0055 | loss 0.9376 | val@20 0.0236 | test@20 0.0033 | best 0.0236 (ep 55)
2025-12-09 19:12:31,383 - [GAT-Baseline] Epoch 0060 | loss 0.9082 | val@20 0.0280 | test@20 0.0176 | best 0.0280 (ep 60)
2025-12-09 19:12:38,069 - [GAT-Baseline] Epoch 0065 | loss 0.8856 | val@20 0.0446 | test@20 0.0146 | best 0.0446 (ep 65)
2025-12-09 19:12:44,768 - [GAT-Baseline] Epoch 0070 | loss 0.8741 | val@20 0.0474 | test@20 0.0167 | best 0.0474 (ep 70)
2025-12-09 19:12:51,479 - [GAT-Baseline] Epoch 0075 | loss 0.8550 | val@20 0.0487 | test@20 0.0192 | best 0.0487 (ep 75)
2025-12-09 19:12:58,161 - [GAT-Baseline] Epoch 0080 | loss 0.8377 | val@20 0.0376 | test@20 0.0143 | best 0.0487 (ep 75)
2025-12-09 19:13:05,028 - [GAT-Baseline] Epoch 0085 | loss 0.8259 | val@20 0.0541 | test@20 0.0246 | best 0.0541 (ep 85)
2025-12-09 19:13:11,749 - [GAT-Baseline] Epoch 0090 | loss 0.8103 | val@20 0.0747 | test@20 0.0359 | best 0.0747 (ep 90)
2025-12-09 19:13:18,428 - [GAT-Baseline] Epoch 0095 | loss 0.8083 | val@20 0.0887 | test@20 0.0387 | best 0.0887 (ep 95)
2025-12-09 19:13:25,136 - [GAT-Baseline] Epoch 0100 | loss 0.7936 | val@20 0.0847 | test@20 0.0342 | best 0.0887 (ep 95)
2025-12-09 19:13:31,806 - [GAT-Baseline] Epoch 0105 | loss 0.8137 | val@20 0.0942 | test@20 0.0358 | best 0.0942 (ep 105)
2025-12-09 19:13:38,459 - [GAT-Baseline] Epoch 0110 | loss 0.7836 | val@20 0.0532 | test@20 0.0226 | best 0.0942 (ep 105)
2025-12-09 19:13:45,198 - [GAT-Baseline] Epoch 0115 | loss 0.7804 | val@20 0.0952 | test@20 0.0361 | best 0.0952 (ep 115)
2025-12-09 19:13:51,913 - [GAT-Baseline] Epoch 0120 | loss 0.7886 | val@20 0.0819 | test@20 0.0316 | best 0.0952 (ep 115)
2025-12-09 19:13:58,565 - [GAT-Baseline] Epoch 0125 | loss 0.7825 | val@20 0.0805 | test@20 0.0287 | best 0.0952 (ep 115)
2025-12-09 19:14:05,327 - [GAT-Baseline] Epoch 0130 | loss 0.7692 | val@20 0.0694 | test@20 0.0261 | best 0.0952 (ep 115)
2025-12-09 19:14:12,021 - [GAT-Baseline] Epoch 0135 | loss 0.7624 | val@20 0.0754 | test@20 0.0282 | best 0.0952 (ep 115)
2025-12-09 19:14:18,731 - [GAT-Baseline] Epoch 0140 | loss 0.7567 | val@20 0.0564 | test@20 0.0253 | best 0.0952 (ep 115)
2025-12-09 19:14:25,406 - [GAT-Baseline] Epoch 0145 | loss 0.7502 | val@20 0.0481 | test@20 0.0190 | best 0.0952 (ep 115)
2025-12-09 19:14:32,085 - [GAT-Baseline] Epoch 0150 | loss 0.7458 | val@20 0.0368 | test@20 0.0176 | best 0.0952 (ep 115)
2025-12-09 19:14:38,767 - [GAT-Baseline] Epoch 0155 | loss 0.7484 | val@20 0.0389 | test@20 0.0199 | best 0.0952 (ep 115)
2025-12-09 19:14:45,449 - [GAT-Baseline] Epoch 0160 | loss 0.7450 | val@20 0.0720 | test@20 0.0269 | best 0.0952 (ep 115)
2025-12-09 19:14:52,153 - [GAT-Baseline] Epoch 0165 | loss 0.7345 | val@20 0.0318 | test@20 0.0234 | best 0.0952 (ep 115)
2025-12-09 19:14:58,859 - [GAT-Baseline] Epoch 0170 | loss 0.7450 | val@20 0.0953 | test@20 0.0488 | best 0.0953 (ep 170)
2025-12-09 19:15:05,647 - [GAT-Baseline] Epoch 0175 | loss 0.7526 | val@20 0.0583 | test@20 0.0354 | best 0.0953 (ep 170)
2025-12-09 19:15:12,341 - [GAT-Baseline] Epoch 0180 | loss 0.7285 | val@20 0.0411 | test@20 0.0314 | best 0.0953 (ep 170)
2025-12-09 19:15:19,021 - [GAT-Baseline] Epoch 0185 | loss 0.7192 | val@20 0.0556 | test@20 0.0430 | best 0.0953 (ep 170)
2025-12-09 19:15:25,702 - [GAT-Baseline] Epoch 0190 | loss 0.7190 | val@20 0.0385 | test@20 0.0272 | best 0.0953 (ep 170)
2025-12-09 19:15:32,419 - [GAT-Baseline] Epoch 0195 | loss 0.7119 | val@20 0.0465 | test@20 0.0387 | best 0.0953 (ep 170)
2025-12-09 19:15:39,098 - [GAT-Baseline] Epoch 0200 | loss 0.7079 | val@20 0.0407 | test@20 0.0319 | best 0.0953 (ep 170)
2025-12-09 19:15:39,098 - [GAT-Baseline] Done. Best val@20=0.0953 | test@20=0.0488 (epoch 170)
2025-12-09 19:15:39,099 - 
================================================================================
2025-12-09 19:15:39,100 - FINAL RESULTS - BASELINES
2025-12-09 19:15:39,100 - ================================================================================
2025-12-09 19:15:39,100 - GCN:
2025-12-09 19:15:39,100 -   Validation Hits@20: 0.1359
2025-12-09 19:15:39,100 -   Test Hits@20: 0.1102
2025-12-09 19:15:39,100 -   Val-Test Gap: 0.0258 (19.0% relative)
2025-12-09 19:15:39,100 - GraphSAGE:
2025-12-09 19:15:39,100 -   Validation Hits@20: 0.0961
2025-12-09 19:15:39,100 -   Test Hits@20: 0.0446
2025-12-09 19:15:39,100 -   Val-Test Gap: 0.0515 (53.6% relative)
2025-12-09 19:15:39,100 - GraphTransformer:
2025-12-09 19:15:39,100 -   Validation Hits@20: 0.1166
2025-12-09 19:15:39,100 -   Test Hits@20: 0.0373
2025-12-09 19:15:39,100 -   Val-Test Gap: 0.0793 (68.0% relative)
2025-12-09 19:15:39,100 - GAT:
2025-12-09 19:15:39,100 -   Validation Hits@20: 0.0953
2025-12-09 19:15:39,101 -   Test Hits@20: 0.0488
2025-12-09 19:15:39,101 -   Val-Test Gap: 0.0465 (48.8% relative)
2025-12-09 19:15:39,101 - ================================================================================
2025-12-09 19:15:39,101 - Results logged to: logs/baselines_20251209_185813/baselines.log
