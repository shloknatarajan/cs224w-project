2025-12-09 04:09:28,283 - Using device: cuda
2025-12-09 04:09:28,283 - Logging results to: logs/baselines_20251209_040928/baselines.log
2025-12-09 04:09:28,283 - Loading dataset ogbl-ddi...
2025-12-09 04:09:28,368 - Dataset loaded: 4267 nodes
2025-12-09 04:09:28,514 - Train pos edges: 1067911, Valid pos: 133489, Test pos: 133489
2025-12-09 04:09:28,514 - Valid neg edges: 101882, Test neg: 95599
2025-12-09 04:09:28,534 - Added self-loops: Total edges now = 1072178
2025-12-09 04:09:28,541 - 
================================================================================
2025-12-09 04:09:28,541 - Training Simple GCN Baseline (minimal trainer)
2025-12-09 04:09:28,541 - ================================================================================
2025-12-09 04:09:28,581 - [GCN-Baseline] Starting minimal baseline training (epochs=200, lr=0.01, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 04:09:30,381 - [GCN-Baseline] Epoch 0001 | loss 1.3912 | val@20 0.0099 | test@20 0.0045 | best 0.0099 (ep 1)
2025-12-09 04:09:35,873 - [GCN-Baseline] Epoch 0005 | loss 1.7010 | val@20 0.0176 | test@20 0.0384 | best 0.0176 (ep 5)
2025-12-09 04:09:42,635 - [GCN-Baseline] Epoch 0010 | loss 1.3634 | val@20 0.0319 | test@20 0.0041 | best 0.0319 (ep 10)
2025-12-09 04:09:49,356 - [GCN-Baseline] Epoch 0015 | loss 1.2845 | val@20 0.0391 | test@20 0.0108 | best 0.0391 (ep 15)
2025-12-09 04:09:56,090 - [GCN-Baseline] Epoch 0020 | loss 1.1156 | val@20 0.0498 | test@20 0.0397 | best 0.0498 (ep 20)
2025-12-09 04:10:02,815 - [GCN-Baseline] Epoch 0025 | loss 1.0708 | val@20 0.0229 | test@20 0.0432 | best 0.0498 (ep 20)
2025-12-09 04:10:09,545 - [GCN-Baseline] Epoch 0030 | loss 0.9697 | val@20 0.0547 | test@20 0.0470 | best 0.0547 (ep 30)
2025-12-09 04:10:16,261 - [GCN-Baseline] Epoch 0035 | loss 0.9244 | val@20 0.0587 | test@20 0.0665 | best 0.0587 (ep 35)
2025-12-09 04:10:23,008 - [GCN-Baseline] Epoch 0040 | loss 0.9027 | val@20 0.0243 | test@20 0.0575 | best 0.0587 (ep 35)
2025-12-09 04:10:29,735 - [GCN-Baseline] Epoch 0045 | loss 0.8776 | val@20 0.0540 | test@20 0.0543 | best 0.0587 (ep 35)
2025-12-09 04:10:36,456 - [GCN-Baseline] Epoch 0050 | loss 0.8571 | val@20 0.0343 | test@20 0.0502 | best 0.0587 (ep 35)
2025-12-09 04:10:43,190 - [GCN-Baseline] Epoch 0055 | loss 0.8298 | val@20 0.0267 | test@20 0.0454 | best 0.0587 (ep 35)
2025-12-09 04:10:49,888 - [GCN-Baseline] Epoch 0060 | loss 0.8351 | val@20 0.0198 | test@20 0.0146 | best 0.0587 (ep 35)
2025-12-09 04:10:56,545 - [GCN-Baseline] Epoch 0065 | loss 0.8268 | val@20 0.0266 | test@20 0.0338 | best 0.0587 (ep 35)
2025-12-09 04:11:03,183 - [GCN-Baseline] Epoch 0070 | loss 0.7891 | val@20 0.0164 | test@20 0.0084 | best 0.0587 (ep 35)
2025-12-09 04:11:09,834 - [GCN-Baseline] Epoch 0075 | loss 0.7855 | val@20 0.0110 | test@20 0.0088 | best 0.0587 (ep 35)
2025-12-09 04:11:16,496 - [GCN-Baseline] Epoch 0080 | loss 0.7715 | val@20 0.0452 | test@20 0.0123 | best 0.0587 (ep 35)
2025-12-09 04:11:23,192 - [GCN-Baseline] Epoch 0085 | loss 0.7558 | val@20 0.0718 | test@20 0.0580 | best 0.0718 (ep 85)
2025-12-09 04:11:29,835 - [GCN-Baseline] Epoch 0090 | loss 0.7503 | val@20 0.0239 | test@20 0.0190 | best 0.0718 (ep 85)
2025-12-09 04:11:36,476 - [GCN-Baseline] Epoch 0095 | loss 0.7444 | val@20 0.0214 | test@20 0.0187 | best 0.0718 (ep 85)
2025-12-09 04:11:43,172 - [GCN-Baseline] Epoch 0100 | loss 0.7353 | val@20 0.0173 | test@20 0.0193 | best 0.0718 (ep 85)
2025-12-09 04:11:49,806 - [GCN-Baseline] Epoch 0105 | loss 0.7283 | val@20 0.0341 | test@20 0.0214 | best 0.0718 (ep 85)
2025-12-09 04:11:56,399 - [GCN-Baseline] Epoch 0110 | loss 0.7823 | val@20 0.0289 | test@20 0.0488 | best 0.0718 (ep 85)
2025-12-09 04:12:02,987 - [GCN-Baseline] Epoch 0115 | loss 0.7396 | val@20 0.1187 | test@20 0.1253 | best 0.1187 (ep 115)
2025-12-09 04:12:09,545 - [GCN-Baseline] Epoch 0120 | loss 0.7216 | val@20 0.0758 | test@20 0.0791 | best 0.1187 (ep 115)
2025-12-09 04:12:16,148 - [GCN-Baseline] Epoch 0125 | loss 0.7260 | val@20 0.0393 | test@20 0.0623 | best 0.1187 (ep 115)
2025-12-09 04:12:22,753 - [GCN-Baseline] Epoch 0130 | loss 0.7146 | val@20 0.0284 | test@20 0.0532 | best 0.1187 (ep 115)
2025-12-09 04:12:29,304 - [GCN-Baseline] Epoch 0135 | loss 0.7079 | val@20 0.0420 | test@20 0.0388 | best 0.1187 (ep 115)
2025-12-09 04:12:35,850 - [GCN-Baseline] Epoch 0140 | loss 0.7004 | val@20 0.0321 | test@20 0.0443 | best 0.1187 (ep 115)
2025-12-09 04:12:42,381 - [GCN-Baseline] Epoch 0145 | loss 0.6923 | val@20 0.0377 | test@20 0.0500 | best 0.1187 (ep 115)
2025-12-09 04:12:48,930 - [GCN-Baseline] Epoch 0150 | loss 0.6887 | val@20 0.0488 | test@20 0.0619 | best 0.1187 (ep 115)
2025-12-09 04:12:55,481 - [GCN-Baseline] Epoch 0155 | loss 0.6795 | val@20 0.0304 | test@20 0.0488 | best 0.1187 (ep 115)
2025-12-09 04:13:02,033 - [GCN-Baseline] Epoch 0160 | loss 0.7284 | val@20 0.0568 | test@20 0.0757 | best 0.1187 (ep 115)
2025-12-09 04:13:08,598 - [GCN-Baseline] Epoch 0165 | loss 0.7007 | val@20 0.1470 | test@20 0.1237 | best 0.1470 (ep 165)
2025-12-09 04:13:15,105 - [GCN-Baseline] Epoch 0170 | loss 0.7130 | val@20 0.1469 | test@20 0.1050 | best 0.1470 (ep 165)
2025-12-09 04:13:21,654 - [GCN-Baseline] Epoch 0175 | loss 0.7036 | val@20 0.0320 | test@20 0.0579 | best 0.1470 (ep 165)
2025-12-09 04:13:28,203 - [GCN-Baseline] Epoch 0180 | loss 0.6861 | val@20 0.1196 | test@20 0.1159 | best 0.1470 (ep 165)
2025-12-09 04:13:34,758 - [GCN-Baseline] Epoch 0185 | loss 0.6676 | val@20 0.0660 | test@20 0.0629 | best 0.1470 (ep 165)
2025-12-09 04:13:41,292 - [GCN-Baseline] Epoch 0190 | loss 0.6579 | val@20 0.0410 | test@20 0.0429 | best 0.1470 (ep 165)
2025-12-09 04:13:47,866 - [GCN-Baseline] Epoch 0195 | loss 0.6521 | val@20 0.0492 | test@20 0.0529 | best 0.1470 (ep 165)
2025-12-09 04:13:54,378 - [GCN-Baseline] Epoch 0200 | loss 0.6469 | val@20 0.0582 | test@20 0.0652 | best 0.1470 (ep 165)
2025-12-09 04:13:54,378 - [GCN-Baseline] Done. Best val@20=0.1470 | test@20=0.1237 (epoch 165)
2025-12-09 04:13:54,378 - 
================================================================================
2025-12-09 04:13:54,378 - Training GraphSAGE Baseline (minimal trainer)
2025-12-09 04:13:54,379 - ================================================================================
2025-12-09 04:13:54,414 - [GraphSAGE-Baseline] Starting minimal baseline training (epochs=200, lr=0.01, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 04:13:55,829 - [GraphSAGE-Baseline] Epoch 0001 | loss 1.3865 | val@20 0.0003 | test@20 0.0011 | best 0.0003 (ep 1)
2025-12-09 04:14:01,060 - [GraphSAGE-Baseline] Epoch 0005 | loss 1.3215 | val@20 0.0098 | test@20 0.0113 | best 0.0098 (ep 5)
2025-12-09 04:14:07,571 - [GraphSAGE-Baseline] Epoch 0010 | loss 1.1484 | val@20 0.0065 | test@20 0.0039 | best 0.0098 (ep 5)
2025-12-09 04:14:14,138 - [GraphSAGE-Baseline] Epoch 0015 | loss 0.9540 | val@20 0.0119 | test@20 0.0193 | best 0.0119 (ep 15)
2025-12-09 04:14:20,716 - [GraphSAGE-Baseline] Epoch 0020 | loss 0.9449 | val@20 0.0240 | test@20 0.0396 | best 0.0240 (ep 20)
2025-12-09 04:14:27,267 - [GraphSAGE-Baseline] Epoch 0025 | loss 0.9095 | val@20 0.0218 | test@20 0.0335 | best 0.0240 (ep 20)
2025-12-09 04:14:33,880 - [GraphSAGE-Baseline] Epoch 0030 | loss 0.8540 | val@20 0.0209 | test@20 0.0185 | best 0.0240 (ep 20)
2025-12-09 04:14:40,433 - [GraphSAGE-Baseline] Epoch 0035 | loss 0.8498 | val@20 0.0353 | test@20 0.0071 | best 0.0353 (ep 35)
2025-12-09 04:14:46,977 - [GraphSAGE-Baseline] Epoch 0040 | loss 0.8268 | val@20 0.0351 | test@20 0.0502 | best 0.0353 (ep 35)
2025-12-09 04:14:53,525 - [GraphSAGE-Baseline] Epoch 0045 | loss 0.8230 | val@20 0.0573 | test@20 0.0287 | best 0.0573 (ep 45)
2025-12-09 04:15:00,089 - [GraphSAGE-Baseline] Epoch 0050 | loss 0.7876 | val@20 0.0139 | test@20 0.0149 | best 0.0573 (ep 45)
2025-12-09 04:15:06,608 - [GraphSAGE-Baseline] Epoch 0055 | loss 0.7701 | val@20 0.0272 | test@20 0.0441 | best 0.0573 (ep 45)
2025-12-09 04:15:13,152 - [GraphSAGE-Baseline] Epoch 0060 | loss 0.7650 | val@20 0.0254 | test@20 0.0349 | best 0.0573 (ep 45)
2025-12-09 04:15:19,751 - [GraphSAGE-Baseline] Epoch 0065 | loss 0.7434 | val@20 0.0292 | test@20 0.0318 | best 0.0573 (ep 45)
2025-12-09 04:15:26,314 - [GraphSAGE-Baseline] Epoch 0070 | loss 0.7296 | val@20 0.0378 | test@20 0.0375 | best 0.0573 (ep 45)
2025-12-09 04:15:32,919 - [GraphSAGE-Baseline] Epoch 0075 | loss 0.7168 | val@20 0.0407 | test@20 0.0325 | best 0.0573 (ep 45)
2025-12-09 04:15:39,424 - [GraphSAGE-Baseline] Epoch 0080 | loss 0.6989 | val@20 0.0924 | test@20 0.0428 | best 0.0924 (ep 80)
2025-12-09 04:15:45,955 - [GraphSAGE-Baseline] Epoch 0085 | loss 0.6925 | val@20 0.0666 | test@20 0.0449 | best 0.0924 (ep 80)
2025-12-09 04:15:52,457 - [GraphSAGE-Baseline] Epoch 0090 | loss 0.6851 | val@20 0.0728 | test@20 0.0279 | best 0.0924 (ep 80)
2025-12-09 04:15:58,956 - [GraphSAGE-Baseline] Epoch 0095 | loss 0.6875 | val@20 0.0896 | test@20 0.0418 | best 0.0924 (ep 80)
2025-12-09 04:16:05,535 - [GraphSAGE-Baseline] Epoch 0100 | loss 0.6737 | val@20 0.1062 | test@20 0.0645 | best 0.1062 (ep 100)
2025-12-09 04:16:12,120 - [GraphSAGE-Baseline] Epoch 0105 | loss 0.6644 | val@20 0.1090 | test@20 0.0365 | best 0.1090 (ep 105)
2025-12-09 04:16:18,622 - [GraphSAGE-Baseline] Epoch 0110 | loss 0.6850 | val@20 0.0770 | test@20 0.0261 | best 0.1090 (ep 105)
2025-12-09 04:16:25,114 - [GraphSAGE-Baseline] Epoch 0115 | loss 0.6833 | val@20 0.0821 | test@20 0.0161 | best 0.1090 (ep 105)
2025-12-09 04:16:31,705 - [GraphSAGE-Baseline] Epoch 0120 | loss 0.6737 | val@20 0.0429 | test@20 0.0871 | best 0.1090 (ep 105)
2025-12-09 04:16:38,273 - [GraphSAGE-Baseline] Epoch 0125 | loss 0.6502 | val@20 0.0689 | test@20 0.0604 | best 0.1090 (ep 105)
2025-12-09 04:16:44,871 - [GraphSAGE-Baseline] Epoch 0130 | loss 0.6374 | val@20 0.0487 | test@20 0.0211 | best 0.1090 (ep 105)
2025-12-09 04:16:51,420 - [GraphSAGE-Baseline] Epoch 0135 | loss 0.6261 | val@20 0.0856 | test@20 0.0366 | best 0.1090 (ep 105)
2025-12-09 04:16:57,977 - [GraphSAGE-Baseline] Epoch 0140 | loss 0.6147 | val@20 0.1022 | test@20 0.0523 | best 0.1090 (ep 105)
2025-12-09 04:17:04,556 - [GraphSAGE-Baseline] Epoch 0145 | loss 0.6049 | val@20 0.0800 | test@20 0.0519 | best 0.1090 (ep 105)
2025-12-09 04:17:11,141 - [GraphSAGE-Baseline] Epoch 0150 | loss 0.5993 | val@20 0.0621 | test@20 0.0397 | best 0.1090 (ep 105)
2025-12-09 04:17:17,697 - [GraphSAGE-Baseline] Epoch 0155 | loss 0.5973 | val@20 0.0309 | test@20 0.0125 | best 0.1090 (ep 105)
2025-12-09 04:17:24,199 - [GraphSAGE-Baseline] Epoch 0160 | loss 0.6131 | val@20 0.0485 | test@20 0.0342 | best 0.1090 (ep 105)
2025-12-09 04:17:30,759 - [GraphSAGE-Baseline] Epoch 0165 | loss 0.5900 | val@20 0.0633 | test@20 0.0278 | best 0.1090 (ep 105)
2025-12-09 04:17:37,257 - [GraphSAGE-Baseline] Epoch 0170 | loss 0.5862 | val@20 0.0511 | test@20 0.0196 | best 0.1090 (ep 105)
2025-12-09 04:17:43,814 - [GraphSAGE-Baseline] Epoch 0175 | loss 0.5709 | val@20 0.0602 | test@20 0.0480 | best 0.1090 (ep 105)
2025-12-09 04:17:50,386 - [GraphSAGE-Baseline] Epoch 0180 | loss 0.5604 | val@20 0.0717 | test@20 0.0569 | best 0.1090 (ep 105)
2025-12-09 04:17:56,943 - [GraphSAGE-Baseline] Epoch 0185 | loss 0.5556 | val@20 0.0774 | test@20 0.0609 | best 0.1090 (ep 105)
2025-12-09 04:18:03,512 - [GraphSAGE-Baseline] Epoch 0190 | loss 0.5466 | val@20 0.0774 | test@20 0.0559 | best 0.1090 (ep 105)
2025-12-09 04:18:10,090 - [GraphSAGE-Baseline] Epoch 0195 | loss 0.5461 | val@20 0.0589 | test@20 0.0402 | best 0.1090 (ep 105)
2025-12-09 04:18:16,642 - [GraphSAGE-Baseline] Epoch 0200 | loss 0.5365 | val@20 0.0523 | test@20 0.0413 | best 0.1090 (ep 105)
2025-12-09 04:18:16,642 - [GraphSAGE-Baseline] Done. Best val@20=0.1090 | test@20=0.0365 (epoch 105)
2025-12-09 04:18:16,642 - 
================================================================================
2025-12-09 04:18:16,642 - Training GraphTransformer Baseline (minimal trainer)
2025-12-09 04:18:16,643 - ================================================================================
2025-12-09 04:18:16,681 - [GraphTransformer-Baseline] Starting minimal baseline training (epochs=200, lr=0.005, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 04:18:18,202 - [GraphTransformer-Baseline] Epoch 0001 | loss 1.3872 | val@20 0.0010 | test@20 0.0002 | best 0.0010 (ep 1)
2025-12-09 04:18:23,725 - [GraphTransformer-Baseline] Epoch 0005 | loss 1.3780 | val@20 0.0158 | test@20 0.0030 | best 0.0158 (ep 5)
2025-12-09 04:18:30,603 - [GraphTransformer-Baseline] Epoch 0010 | loss 1.2620 | val@20 0.0085 | test@20 0.0096 | best 0.0158 (ep 5)
2025-12-09 04:18:37,469 - [GraphTransformer-Baseline] Epoch 0015 | loss 1.1168 | val@20 0.0060 | test@20 0.0044 | best 0.0158 (ep 5)
2025-12-09 04:18:44,296 - [GraphTransformer-Baseline] Epoch 0020 | loss 1.0019 | val@20 0.0081 | test@20 0.0071 | best 0.0158 (ep 5)
2025-12-09 04:18:51,155 - [GraphTransformer-Baseline] Epoch 0025 | loss 0.9530 | val@20 0.0099 | test@20 0.0103 | best 0.0158 (ep 5)
2025-12-09 04:18:58,004 - [GraphTransformer-Baseline] Epoch 0030 | loss 0.9200 | val@20 0.0163 | test@20 0.0205 | best 0.0163 (ep 30)
2025-12-09 04:19:04,855 - [GraphTransformer-Baseline] Epoch 0035 | loss 0.8896 | val@20 0.0262 | test@20 0.0385 | best 0.0262 (ep 35)
2025-12-09 04:19:11,706 - [GraphTransformer-Baseline] Epoch 0040 | loss 0.8627 | val@20 0.0001 | test@20 0.0000 | best 0.0262 (ep 35)
2025-12-09 04:19:18,560 - [GraphTransformer-Baseline] Epoch 0045 | loss 0.8741 | val@20 0.0245 | test@20 0.0210 | best 0.0262 (ep 35)
2025-12-09 04:19:25,414 - [GraphTransformer-Baseline] Epoch 0050 | loss 0.8371 | val@20 0.0353 | test@20 0.0412 | best 0.0353 (ep 50)
2025-12-09 04:19:32,271 - [GraphTransformer-Baseline] Epoch 0055 | loss 0.8130 | val@20 0.0337 | test@20 0.0420 | best 0.0353 (ep 50)
2025-12-09 04:19:39,139 - [GraphTransformer-Baseline] Epoch 0060 | loss 0.8066 | val@20 0.0477 | test@20 0.0387 | best 0.0477 (ep 60)
2025-12-09 04:19:46,017 - [GraphTransformer-Baseline] Epoch 0065 | loss 0.8133 | val@20 0.0541 | test@20 0.0215 | best 0.0541 (ep 65)
2025-12-09 04:19:52,892 - [GraphTransformer-Baseline] Epoch 0070 | loss 0.7978 | val@20 0.0343 | test@20 0.0500 | best 0.0541 (ep 65)
2025-12-09 04:19:59,772 - [GraphTransformer-Baseline] Epoch 0075 | loss 0.7814 | val@20 0.0403 | test@20 0.0475 | best 0.0541 (ep 65)
2025-12-09 04:20:06,624 - [GraphTransformer-Baseline] Epoch 0080 | loss 0.7629 | val@20 0.0129 | test@20 0.0069 | best 0.0541 (ep 65)
2025-12-09 04:20:13,489 - [GraphTransformer-Baseline] Epoch 0085 | loss 0.7488 | val@20 0.0068 | test@20 0.0022 | best 0.0541 (ep 65)
2025-12-09 04:20:20,362 - [GraphTransformer-Baseline] Epoch 0090 | loss 0.9066 | val@20 0.0361 | test@20 0.0060 | best 0.0541 (ep 65)
2025-12-09 04:20:27,225 - [GraphTransformer-Baseline] Epoch 0095 | loss 0.8080 | val@20 0.0260 | test@20 0.0411 | best 0.0541 (ep 65)
2025-12-09 04:20:34,123 - [GraphTransformer-Baseline] Epoch 0100 | loss 0.7727 | val@20 0.0567 | test@20 0.0191 | best 0.0567 (ep 100)
2025-12-09 04:20:41,001 - [GraphTransformer-Baseline] Epoch 0105 | loss 0.7450 | val@20 0.0294 | test@20 0.0449 | best 0.0567 (ep 100)
2025-12-09 04:20:47,877 - [GraphTransformer-Baseline] Epoch 0110 | loss 0.7240 | val@20 0.0298 | test@20 0.0425 | best 0.0567 (ep 100)
2025-12-09 04:20:54,737 - [GraphTransformer-Baseline] Epoch 0115 | loss 0.7115 | val@20 0.0567 | test@20 0.0472 | best 0.0567 (ep 100)
2025-12-09 04:21:01,621 - [GraphTransformer-Baseline] Epoch 0120 | loss 0.7008 | val@20 0.0654 | test@20 0.0616 | best 0.0654 (ep 120)
2025-12-09 04:21:08,484 - [GraphTransformer-Baseline] Epoch 0125 | loss 0.6896 | val@20 0.0698 | test@20 0.0612 | best 0.0698 (ep 125)
2025-12-09 04:21:15,340 - [GraphTransformer-Baseline] Epoch 0130 | loss 0.6824 | val@20 0.0620 | test@20 0.0420 | best 0.0698 (ep 125)
2025-12-09 04:21:22,197 - [GraphTransformer-Baseline] Epoch 0135 | loss 0.6752 | val@20 0.0708 | test@20 0.0498 | best 0.0708 (ep 135)
2025-12-09 04:21:29,078 - [GraphTransformer-Baseline] Epoch 0140 | loss 0.6698 | val@20 0.0582 | test@20 0.0492 | best 0.0708 (ep 135)
2025-12-09 04:21:36,014 - [GraphTransformer-Baseline] Epoch 0145 | loss 0.6638 | val@20 0.0601 | test@20 0.0455 | best 0.0708 (ep 135)
2025-12-09 04:21:42,993 - [GraphTransformer-Baseline] Epoch 0150 | loss 0.6603 | val@20 0.0654 | test@20 0.0406 | best 0.0708 (ep 135)
2025-12-09 04:21:49,979 - [GraphTransformer-Baseline] Epoch 0155 | loss 0.6542 | val@20 0.0568 | test@20 0.0376 | best 0.0708 (ep 135)
2025-12-09 04:21:56,846 - [GraphTransformer-Baseline] Epoch 0160 | loss 0.6504 | val@20 0.0616 | test@20 0.0360 | best 0.0708 (ep 135)
2025-12-09 04:22:03,696 - [GraphTransformer-Baseline] Epoch 0165 | loss 0.6485 | val@20 0.0763 | test@20 0.0426 | best 0.0763 (ep 165)
2025-12-09 04:22:10,548 - [GraphTransformer-Baseline] Epoch 0170 | loss 0.6434 | val@20 0.0451 | test@20 0.0381 | best 0.0763 (ep 165)
2025-12-09 04:22:17,388 - [GraphTransformer-Baseline] Epoch 0175 | loss 0.6442 | val@20 0.0554 | test@20 0.0495 | best 0.0763 (ep 165)
2025-12-09 04:22:24,262 - [GraphTransformer-Baseline] Epoch 0180 | loss 0.6620 | val@20 0.0650 | test@20 0.0288 | best 0.0763 (ep 165)
2025-12-09 04:22:31,112 - [GraphTransformer-Baseline] Epoch 0185 | loss 0.6363 | val@20 0.0853 | test@20 0.0399 | best 0.0853 (ep 185)
2025-12-09 04:22:37,965 - [GraphTransformer-Baseline] Epoch 0190 | loss 0.6385 | val@20 0.0661 | test@20 0.0430 | best 0.0853 (ep 185)
2025-12-09 04:22:44,820 - [GraphTransformer-Baseline] Epoch 0195 | loss 0.6209 | val@20 0.0697 | test@20 0.0246 | best 0.0853 (ep 185)
2025-12-09 04:22:51,740 - [GraphTransformer-Baseline] Epoch 0200 | loss 0.6115 | val@20 0.0907 | test@20 0.0439 | best 0.0907 (ep 200)
2025-12-09 04:22:51,740 - [GraphTransformer-Baseline] Done. Best val@20=0.0907 | test@20=0.0439 (epoch 200)
2025-12-09 04:22:51,740 - 
================================================================================
2025-12-09 04:22:51,741 - Training GAT Baseline (minimal trainer)
2025-12-09 04:22:51,741 - ================================================================================
2025-12-09 04:22:51,901 - [GAT-Baseline] Starting minimal baseline training (epochs=200, lr=0.005, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 04:22:53,379 - [GAT-Baseline] Epoch 0001 | loss 1.3884 | val@20 0.0010 | test@20 0.0003 | best 0.0010 (ep 1)
2025-12-09 04:22:58,823 - [GAT-Baseline] Epoch 0005 | loss 1.3856 | val@20 0.0039 | test@20 0.0007 | best 0.0039 (ep 5)
2025-12-09 04:23:05,497 - [GAT-Baseline] Epoch 0010 | loss 1.3605 | val@20 0.0011 | test@20 0.0003 | best 0.0039 (ep 5)
2025-12-09 04:23:12,202 - [GAT-Baseline] Epoch 0015 | loss 1.2865 | val@20 0.0007 | test@20 0.0003 | best 0.0039 (ep 5)
2025-12-09 04:23:19,003 - [GAT-Baseline] Epoch 0020 | loss 1.2181 | val@20 0.0001 | test@20 0.0001 | best 0.0039 (ep 5)
2025-12-09 04:23:25,708 - [GAT-Baseline] Epoch 0025 | loss 1.1001 | val@20 0.0012 | test@20 0.0061 | best 0.0039 (ep 5)
2025-12-09 04:23:32,378 - [GAT-Baseline] Epoch 0030 | loss 1.0451 | val@20 0.0078 | test@20 0.0027 | best 0.0078 (ep 30)
2025-12-09 04:23:39,097 - [GAT-Baseline] Epoch 0035 | loss 1.0035 | val@20 0.0090 | test@20 0.0034 | best 0.0090 (ep 35)
2025-12-09 04:23:45,811 - [GAT-Baseline] Epoch 0040 | loss 0.9815 | val@20 0.0027 | test@20 0.0017 | best 0.0090 (ep 35)
2025-12-09 04:23:52,473 - [GAT-Baseline] Epoch 0045 | loss 0.9573 | val@20 0.1315 | test@20 0.1198 | best 0.1315 (ep 45)
2025-12-09 04:23:59,214 - [GAT-Baseline] Epoch 0050 | loss 0.9417 | val@20 0.1659 | test@20 0.0780 | best 0.1659 (ep 50)
2025-12-09 04:24:05,888 - [GAT-Baseline] Epoch 0055 | loss 0.9308 | val@20 0.0265 | test@20 0.0335 | best 0.1659 (ep 50)
2025-12-09 04:24:12,556 - [GAT-Baseline] Epoch 0060 | loss 0.9259 | val@20 0.1750 | test@20 0.0734 | best 0.1750 (ep 60)
2025-12-09 04:24:19,289 - [GAT-Baseline] Epoch 0065 | loss 0.9205 | val@20 0.0671 | test@20 0.0411 | best 0.1750 (ep 60)
2025-12-09 04:24:26,041 - [GAT-Baseline] Epoch 0070 | loss 0.9191 | val@20 0.0669 | test@20 0.0223 | best 0.1750 (ep 60)
2025-12-09 04:24:32,740 - [GAT-Baseline] Epoch 0075 | loss 0.9146 | val@20 0.1458 | test@20 0.0405 | best 0.1750 (ep 60)
2025-12-09 04:24:39,528 - [GAT-Baseline] Epoch 0080 | loss 0.9119 | val@20 0.0586 | test@20 0.0316 | best 0.1750 (ep 60)
2025-12-09 04:24:46,225 - [GAT-Baseline] Epoch 0085 | loss 0.9074 | val@20 0.0266 | test@20 0.0037 | best 0.1750 (ep 60)
2025-12-09 04:24:52,961 - [GAT-Baseline] Epoch 0090 | loss 0.9054 | val@20 0.0256 | test@20 0.0038 | best 0.1750 (ep 60)
2025-12-09 04:24:59,751 - [GAT-Baseline] Epoch 0095 | loss 0.9005 | val@20 0.1381 | test@20 0.0434 | best 0.1750 (ep 60)
2025-12-09 04:25:06,554 - [GAT-Baseline] Epoch 0100 | loss 0.9134 | val@20 0.1864 | test@20 0.0503 | best 0.1864 (ep 100)
2025-12-09 04:25:13,307 - [GAT-Baseline] Epoch 0105 | loss 0.8952 | val@20 0.1810 | test@20 0.0549 | best 0.1864 (ep 100)
2025-12-09 04:25:19,999 - [GAT-Baseline] Epoch 0110 | loss 0.8851 | val@20 0.1812 | test@20 0.0533 | best 0.1864 (ep 100)
2025-12-09 04:25:26,699 - [GAT-Baseline] Epoch 0115 | loss 0.8789 | val@20 0.0659 | test@20 0.0291 | best 0.1864 (ep 100)
2025-12-09 04:25:33,394 - [GAT-Baseline] Epoch 0120 | loss 0.8742 | val@20 0.1824 | test@20 0.0512 | best 0.1864 (ep 100)
2025-12-09 04:25:40,096 - [GAT-Baseline] Epoch 0125 | loss 0.8700 | val@20 0.1749 | test@20 0.0544 | best 0.1864 (ep 100)
2025-12-09 04:25:46,780 - [GAT-Baseline] Epoch 0130 | loss 0.8672 | val@20 0.0892 | test@20 0.0559 | best 0.1864 (ep 100)
2025-12-09 04:25:53,482 - [GAT-Baseline] Epoch 0135 | loss 0.8627 | val@20 0.1398 | test@20 0.0470 | best 0.1864 (ep 100)
2025-12-09 04:26:00,207 - [GAT-Baseline] Epoch 0140 | loss 0.8599 | val@20 0.0663 | test@20 0.0369 | best 0.1864 (ep 100)
2025-12-09 04:26:06,957 - [GAT-Baseline] Epoch 0145 | loss 0.8555 | val@20 0.0641 | test@20 0.0375 | best 0.1864 (ep 100)
2025-12-09 04:26:13,647 - [GAT-Baseline] Epoch 0150 | loss 0.8527 | val@20 0.0628 | test@20 0.0237 | best 0.1864 (ep 100)
2025-12-09 04:26:20,349 - [GAT-Baseline] Epoch 0155 | loss 0.8504 | val@20 0.0459 | test@20 0.0212 | best 0.1864 (ep 100)
2025-12-09 04:26:27,041 - [GAT-Baseline] Epoch 0160 | loss 0.8463 | val@20 0.0399 | test@20 0.0185 | best 0.1864 (ep 100)
2025-12-09 04:26:33,740 - [GAT-Baseline] Epoch 0165 | loss 0.8425 | val@20 0.0366 | test@20 0.0119 | best 0.1864 (ep 100)
2025-12-09 04:26:40,454 - [GAT-Baseline] Epoch 0170 | loss 0.8398 | val@20 0.0380 | test@20 0.0125 | best 0.1864 (ep 100)
2025-12-09 04:26:47,111 - [GAT-Baseline] Epoch 0175 | loss 0.8368 | val@20 0.0252 | test@20 0.0092 | best 0.1864 (ep 100)
2025-12-09 04:26:53,847 - [GAT-Baseline] Epoch 0180 | loss 0.8314 | val@20 0.0182 | test@20 0.0085 | best 0.1864 (ep 100)
2025-12-09 04:27:00,520 - [GAT-Baseline] Epoch 0185 | loss 0.8309 | val@20 0.0392 | test@20 0.0102 | best 0.1864 (ep 100)
2025-12-09 04:27:07,260 - [GAT-Baseline] Epoch 0190 | loss 0.8231 | val@20 0.0401 | test@20 0.0093 | best 0.1864 (ep 100)
2025-12-09 04:27:13,956 - [GAT-Baseline] Epoch 0195 | loss 0.8453 | val@20 0.0259 | test@20 0.0039 | best 0.1864 (ep 100)
2025-12-09 04:27:20,646 - [GAT-Baseline] Epoch 0200 | loss 0.8451 | val@20 0.1234 | test@20 0.0171 | best 0.1864 (ep 100)
2025-12-09 04:27:20,647 - [GAT-Baseline] Early stopping at epoch 200 (no val improvement for 20 evals)
2025-12-09 04:27:20,647 - [GAT-Baseline] Done. Best val@20=0.1864 | test@20=0.0503 (epoch 100)
2025-12-09 04:27:20,647 - 
================================================================================
2025-12-09 04:27:20,647 - FINAL RESULTS - BASELINES
2025-12-09 04:27:20,647 - ================================================================================
2025-12-09 04:27:20,647 - GCN:
2025-12-09 04:27:20,648 -   Validation Hits@20: 0.1470
2025-12-09 04:27:20,648 -   Test Hits@20: 0.1237
2025-12-09 04:27:20,648 -   Val-Test Gap: 0.0233 (15.8% relative)
2025-12-09 04:27:20,648 - GraphSAGE:
2025-12-09 04:27:20,648 -   Validation Hits@20: 0.1090
2025-12-09 04:27:20,648 -   Test Hits@20: 0.0365
2025-12-09 04:27:20,648 -   Val-Test Gap: 0.0725 (66.5% relative)
2025-12-09 04:27:20,648 - GraphTransformer:
2025-12-09 04:27:20,648 -   Validation Hits@20: 0.0907
2025-12-09 04:27:20,648 -   Test Hits@20: 0.0439
2025-12-09 04:27:20,648 -   Val-Test Gap: 0.0468 (51.6% relative)
2025-12-09 04:27:20,648 - GAT:
2025-12-09 04:27:20,648 -   Validation Hits@20: 0.1864
2025-12-09 04:27:20,648 -   Test Hits@20: 0.0503
2025-12-09 04:27:20,649 -   Val-Test Gap: 0.1360 (73.0% relative)
2025-12-09 04:27:20,649 - ================================================================================
2025-12-09 04:27:20,649 - Results logged to: logs/baselines_20251209_040928/baselines.log
