2025-12-09 16:54:50,738 - Using device: cuda
2025-12-09 16:54:50,738 - Logging results to: logs/baselines_20251209_165450/baselines.log
2025-12-09 16:54:50,738 - Loading dataset ogbl-ddi...
2025-12-09 16:54:50,825 - Dataset loaded: 4267 nodes
2025-12-09 16:54:50,970 - Train pos edges: 1067911, Valid pos: 133489, Test pos: 133489
2025-12-09 16:54:50,970 - Valid neg edges: 101882, Test neg: 95599
2025-12-09 16:54:50,990 - Added self-loops: Total edges now = 1072178
2025-12-09 16:54:50,997 - 
================================================================================
2025-12-09 16:54:50,998 - Training Simple GCN Baseline (minimal trainer)
2025-12-09 16:54:50,998 - ================================================================================
2025-12-09 16:54:51,038 - [GCN-Baseline] Starting minimal baseline training (epochs=200, lr=0.01, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 16:54:52,826 - [GCN-Baseline] Epoch 0001 | loss 1.3905 | val@20 0.0139 | test@20 0.0112 | best 0.0139 (ep 1)
2025-12-09 16:54:58,303 - [GCN-Baseline] Epoch 0005 | loss 1.2574 | val@20 0.0237 | test@20 0.0532 | best 0.0237 (ep 5)
2025-12-09 16:55:05,026 - [GCN-Baseline] Epoch 0010 | loss 1.1731 | val@20 0.0313 | test@20 0.0492 | best 0.0313 (ep 10)
2025-12-09 16:55:11,789 - [GCN-Baseline] Epoch 0015 | loss 1.0656 | val@20 0.0548 | test@20 0.0583 | best 0.0548 (ep 15)
2025-12-09 16:55:18,479 - [GCN-Baseline] Epoch 0020 | loss 0.9779 | val@20 0.0622 | test@20 0.0669 | best 0.0622 (ep 20)
2025-12-09 16:55:25,212 - [GCN-Baseline] Epoch 0025 | loss 0.9181 | val@20 0.0505 | test@20 0.0594 | best 0.0622 (ep 20)
2025-12-09 16:55:31,917 - [GCN-Baseline] Epoch 0030 | loss 0.9098 | val@20 0.0267 | test@20 0.0576 | best 0.0622 (ep 20)
2025-12-09 16:55:38,682 - [GCN-Baseline] Epoch 0035 | loss 0.8921 | val@20 0.0387 | test@20 0.0333 | best 0.0622 (ep 20)
2025-12-09 16:55:45,395 - [GCN-Baseline] Epoch 0040 | loss 0.8425 | val@20 0.0261 | test@20 0.0465 | best 0.0622 (ep 20)
2025-12-09 16:55:52,120 - [GCN-Baseline] Epoch 0045 | loss 0.8286 | val@20 0.0423 | test@20 0.0679 | best 0.0622 (ep 20)
2025-12-09 16:55:58,776 - [GCN-Baseline] Epoch 0050 | loss 0.8220 | val@20 0.0608 | test@20 0.0854 | best 0.0622 (ep 20)
2025-12-09 16:56:05,415 - [GCN-Baseline] Epoch 0055 | loss 0.8070 | val@20 0.0244 | test@20 0.0264 | best 0.0622 (ep 20)
2025-12-09 16:56:12,009 - [GCN-Baseline] Epoch 0060 | loss 0.7911 | val@20 0.0282 | test@20 0.0329 | best 0.0622 (ep 20)
2025-12-09 16:56:18,600 - [GCN-Baseline] Epoch 0065 | loss 0.7806 | val@20 0.0321 | test@20 0.0393 | best 0.0622 (ep 20)
2025-12-09 16:56:25,169 - [GCN-Baseline] Epoch 0070 | loss 0.7718 | val@20 0.0642 | test@20 0.0470 | best 0.0642 (ep 70)
2025-12-09 16:56:31,742 - [GCN-Baseline] Epoch 0075 | loss 0.7578 | val@20 0.0322 | test@20 0.0471 | best 0.0642 (ep 70)
2025-12-09 16:56:38,346 - [GCN-Baseline] Epoch 0080 | loss 0.7970 | val@20 0.0931 | test@20 0.1070 | best 0.0931 (ep 80)
2025-12-09 16:56:44,954 - [GCN-Baseline] Epoch 0085 | loss 0.7649 | val@20 0.0541 | test@20 0.0855 | best 0.0931 (ep 80)
2025-12-09 16:56:51,520 - [GCN-Baseline] Epoch 0090 | loss 0.7483 | val@20 0.0426 | test@20 0.0821 | best 0.0931 (ep 80)
2025-12-09 16:56:58,115 - [GCN-Baseline] Epoch 0095 | loss 0.7419 | val@20 0.0577 | test@20 0.0745 | best 0.0931 (ep 80)
2025-12-09 16:57:04,689 - [GCN-Baseline] Epoch 0100 | loss 0.7338 | val@20 0.0536 | test@20 0.0761 | best 0.0931 (ep 80)
2025-12-09 16:57:11,284 - [GCN-Baseline] Epoch 0105 | loss 0.7230 | val@20 0.0494 | test@20 0.0663 | best 0.0931 (ep 80)
2025-12-09 16:57:17,878 - [GCN-Baseline] Epoch 0110 | loss 0.7164 | val@20 0.0531 | test@20 0.0730 | best 0.0931 (ep 80)
2025-12-09 16:57:24,539 - [GCN-Baseline] Epoch 0115 | loss 0.7163 | val@20 0.0580 | test@20 0.0722 | best 0.0931 (ep 80)
2025-12-09 16:57:31,157 - [GCN-Baseline] Epoch 0120 | loss 0.6982 | val@20 0.0636 | test@20 0.0780 | best 0.0931 (ep 80)
2025-12-09 16:57:37,731 - [GCN-Baseline] Epoch 0125 | loss 0.6870 | val@20 0.1173 | test@20 0.1305 | best 0.1173 (ep 125)
2025-12-09 16:57:44,294 - [GCN-Baseline] Epoch 0130 | loss 0.6975 | val@20 0.1260 | test@20 0.1259 | best 0.1260 (ep 130)
2025-12-09 16:57:50,864 - [GCN-Baseline] Epoch 0135 | loss 0.6749 | val@20 0.0839 | test@20 0.0378 | best 0.1260 (ep 130)
2025-12-09 16:57:57,454 - [GCN-Baseline] Epoch 0140 | loss 0.6762 | val@20 0.0490 | test@20 0.0529 | best 0.1260 (ep 130)
2025-12-09 16:58:04,087 - [GCN-Baseline] Epoch 0145 | loss 0.6597 | val@20 0.0749 | test@20 0.0994 | best 0.1260 (ep 130)
2025-12-09 16:58:10,676 - [GCN-Baseline] Epoch 0150 | loss 0.6580 | val@20 0.0591 | test@20 0.0744 | best 0.1260 (ep 130)
2025-12-09 16:58:17,575 - [GCN-Baseline] Epoch 0155 | loss 0.6466 | val@20 0.0453 | test@20 0.0941 | best 0.1260 (ep 130)
2025-12-09 16:58:24,134 - [GCN-Baseline] Epoch 0160 | loss 0.6590 | val@20 0.0436 | test@20 0.1046 | best 0.1260 (ep 130)
2025-12-09 16:58:30,695 - [GCN-Baseline] Epoch 0165 | loss 0.6841 | val@20 0.1116 | test@20 0.1724 | best 0.1260 (ep 130)
2025-12-09 16:58:37,260 - [GCN-Baseline] Epoch 0170 | loss 0.6399 | val@20 0.1228 | test@20 0.1766 | best 0.1260 (ep 130)
2025-12-09 16:58:43,874 - [GCN-Baseline] Epoch 0175 | loss 0.6748 | val@20 0.0883 | test@20 0.0869 | best 0.1260 (ep 130)
2025-12-09 16:58:50,409 - [GCN-Baseline] Epoch 0180 | loss 0.6323 | val@20 0.0667 | test@20 0.1282 | best 0.1260 (ep 130)
2025-12-09 16:58:56,934 - [GCN-Baseline] Epoch 0185 | loss 0.6348 | val@20 0.0514 | test@20 0.0788 | best 0.1260 (ep 130)
2025-12-09 16:59:03,462 - [GCN-Baseline] Epoch 0190 | loss 0.6220 | val@20 0.0651 | test@20 0.0922 | best 0.1260 (ep 130)
2025-12-09 16:59:09,977 - [GCN-Baseline] Epoch 0195 | loss 0.6153 | val@20 0.0377 | test@20 0.0572 | best 0.1260 (ep 130)
2025-12-09 16:59:16,490 - [GCN-Baseline] Epoch 0200 | loss 0.6126 | val@20 0.0578 | test@20 0.0706 | best 0.1260 (ep 130)
2025-12-09 16:59:16,490 - [GCN-Baseline] Done. Best val@20=0.1260 | test@20=0.1259 (epoch 130)
2025-12-09 16:59:16,491 - 
================================================================================
2025-12-09 16:59:16,491 - Training GraphSAGE Baseline (minimal trainer)
2025-12-09 16:59:16,491 - ================================================================================
2025-12-09 16:59:16,530 - [GraphSAGE-Baseline] Starting minimal baseline training (epochs=200, lr=0.01, wd=0.0001, batch_size=50000, eval_every=5)
2025-12-09 16:59:17,939 - [GraphSAGE-Baseline] Epoch 0001 | loss 1.3899 | val@20 0.0000 | test@20 0.0001 | best 0.0000 (ep 1)
2025-12-09 16:59:23,144 - [GraphSAGE-Baseline] Epoch 0005 | loss 1.3358 | val@20 0.0035 | test@20 0.0036 | best 0.0035 (ep 5)
2025-12-09 16:59:29,682 - [GraphSAGE-Baseline] Epoch 0010 | loss 1.1754 | val@20 0.0010 | test@20 0.0001 | best 0.0035 (ep 5)
2025-12-09 16:59:36,167 - [GraphSAGE-Baseline] Epoch 0015 | loss 0.9891 | val@20 0.0076 | test@20 0.0069 | best 0.0076 (ep 15)
2025-12-09 16:59:42,712 - [GraphSAGE-Baseline] Epoch 0020 | loss 0.9277 | val@20 0.0165 | test@20 0.0165 | best 0.0165 (ep 20)
2025-12-09 16:59:49,352 - [GraphSAGE-Baseline] Epoch 0025 | loss 0.8970 | val@20 0.0044 | test@20 0.0006 | best 0.0165 (ep 20)
2025-12-09 16:59:55,968 - [GraphSAGE-Baseline] Epoch 0030 | loss 0.8686 | val@20 0.0293 | test@20 0.0459 | best 0.0293 (ep 30)
2025-12-09 17:00:02,526 - [GraphSAGE-Baseline] Epoch 0035 | loss 0.8462 | val@20 0.0337 | test@20 0.0446 | best 0.0337 (ep 35)
2025-12-09 17:00:09,039 - [GraphSAGE-Baseline] Epoch 0040 | loss 0.8182 | val@20 0.0532 | test@20 0.0184 | best 0.0532 (ep 40)
2025-12-09 17:00:15,623 - [GraphSAGE-Baseline] Epoch 0045 | loss 0.8239 | val@20 0.0525 | test@20 0.0245 | best 0.0532 (ep 40)
2025-12-09 17:00:22,151 - [GraphSAGE-Baseline] Epoch 0050 | loss 0.8181 | val@20 0.0395 | test@20 0.0553 | best 0.0532 (ep 40)
2025-12-09 17:00:28,793 - [GraphSAGE-Baseline] Epoch 0055 | loss 0.7956 | val@20 0.0187 | test@20 0.0118 | best 0.0532 (ep 40)
2025-12-09 17:00:35,396 - [GraphSAGE-Baseline] Epoch 0060 | loss 0.7618 | val@20 0.0116 | test@20 0.0100 | best 0.0532 (ep 40)
2025-12-09 17:00:41,936 - [GraphSAGE-Baseline] Epoch 0065 | loss 0.7371 | val@20 0.0155 | test@20 0.0180 | best 0.0532 (ep 40)
2025-12-09 17:00:48,474 - [GraphSAGE-Baseline] Epoch 0070 | loss 0.7563 | val@20 0.0736 | test@20 0.0621 | best 0.0736 (ep 70)
2025-12-09 17:00:54,994 - [GraphSAGE-Baseline] Epoch 0075 | loss 0.7312 | val@20 0.0506 | test@20 0.0391 | best 0.0736 (ep 70)
2025-12-09 17:01:01,508 - [GraphSAGE-Baseline] Epoch 0080 | loss 0.7221 | val@20 0.0512 | test@20 0.0393 | best 0.0736 (ep 70)
2025-12-09 17:01:08,092 - [GraphSAGE-Baseline] Epoch 0085 | loss 0.7020 | val@20 0.0621 | test@20 0.0350 | best 0.0736 (ep 70)
2025-12-09 17:01:14,637 - [GraphSAGE-Baseline] Epoch 0090 | loss 0.6878 | val@20 0.1177 | test@20 0.0408 | best 0.1177 (ep 90)
2025-12-09 17:01:21,258 - [GraphSAGE-Baseline] Epoch 0095 | loss 0.6788 | val@20 0.0946 | test@20 0.0283 | best 0.1177 (ep 90)
2025-12-09 17:01:27,815 - [GraphSAGE-Baseline] Epoch 0100 | loss 0.6688 | val@20 0.0666 | test@20 0.0203 | best 0.1177 (ep 90)
2025-12-09 17:01:34,375 - [GraphSAGE-Baseline] Epoch 0105 | loss 0.6588 | val@20 0.0646 | test@20 0.0333 | best 0.1177 (ep 90)
2025-12-09 17:01:40,952 - [GraphSAGE-Baseline] Epoch 0110 | loss 0.6516 | val@20 0.0500 | test@20 0.0304 | best 0.1177 (ep 90)
2025-12-09 17:01:47,547 - [GraphSAGE-Baseline] Epoch 0115 | loss 0.6576 | val@20 0.0404 | test@20 0.0207 | best 0.1177 (ep 90)
2025-12-09 17:01:54,183 - [GraphSAGE-Baseline] Epoch 0120 | loss 0.6435 | val@20 0.0652 | test@20 0.0311 | best 0.1177 (ep 90)
2025-12-09 17:02:00,739 - [GraphSAGE-Baseline] Epoch 0125 | loss 0.6380 | val@20 0.0876 | test@20 0.0583 | best 0.1177 (ep 90)
2025-12-09 17:02:07,213 - [GraphSAGE-Baseline] Epoch 0130 | loss 0.6307 | val@20 0.1090 | test@20 0.0472 | best 0.1177 (ep 90)
2025-12-09 17:02:13,790 - [GraphSAGE-Baseline] Epoch 0135 | loss 0.6388 | val@20 0.0589 | test@20 0.0202 | best 0.1177 (ep 90)
2025-12-09 17:02:20,371 - [GraphSAGE-Baseline] Epoch 0140 | loss 0.6090 | val@20 0.0961 | test@20 0.0394 | best 0.1177 (ep 90)
2025-12-09 17:02:26,960 - [GraphSAGE-Baseline] Epoch 0145 | loss 0.6065 | val@20 0.0685 | test@20 0.0395 | best 0.1177 (ep 90)
2025-12-09 17:02:33,537 - [GraphSAGE-Baseline] Epoch 0150 | loss 0.6767 | val@20 0.0842 | test@20 0.0634 | best 0.1177 (ep 90)
2025-12-09 17:02:40,147 - [GraphSAGE-Baseline] Epoch 0155 | loss 0.6424 | val@20 0.1445 | test@20 0.1021 | best 0.1445 (ep 155)
2025-12-09 17:02:46,771 - [GraphSAGE-Baseline] Epoch 0160 | loss 0.6096 | val@20 0.0208 | test@20 0.0145 | best 0.1445 (ep 155)
2025-12-09 17:02:53,407 - [GraphSAGE-Baseline] Epoch 0165 | loss 0.5921 | val@20 0.0773 | test@20 0.0575 | best 0.1445 (ep 155)
